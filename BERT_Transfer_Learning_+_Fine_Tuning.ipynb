{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT Transfer Learning + Fine Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By0nQhUP0E1y",
        "outputId": "2f147851-4b6d-4ee1-ccc2-da7add8be7a8"
      },
      "source": [
        "# Set up GPU\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_3ySDyO126z",
        "outputId": "76bb0632-f65a-424f-cb14-3a0b1c984fc0"
      },
      "source": [
        "#Install transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLWqNnYN2jOX",
        "outputId": "afde68de-35a3-4e1b-a4e2-c107b0538537"
      },
      "source": [
        "#download and set-up IMDB data\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "(ds_train, ds_test), ds_info = tfds.load('imdb_reviews', \n",
        "          split = (tfds.Split.TRAIN, tfds.Split.TEST),\n",
        "          as_supervised=True,\n",
        "          with_info=True)\n",
        "print('info', ds_info)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: imdb_reviews/plain_text\n",
            "INFO:absl:Load dataset info from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset imdb_reviews (/root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split (Split('train'), Split('test')), from /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "info tfds.core.DatasetInfo(\n",
            "    name='imdb_reviews',\n",
            "    version=1.0.0,\n",
            "    description='Large Movie Review Dataset.\n",
            "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
            "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
            "    features=FeaturesDict({\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
            "        'text': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=100000,\n",
            "    splits={\n",
            "        'test': 25000,\n",
            "        'train': 25000,\n",
            "        'unsupervised': 50000,\n",
            "    },\n",
            "    supervised_keys=('text', 'label'),\n",
            "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
            "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
            "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
            "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
            "      month     = {June},\n",
            "      year      = {2011},\n",
            "      address   = {Portland, Oregon, USA},\n",
            "      publisher = {Association for Computational Linguistics},\n",
            "      pages     = {142--150},\n",
            "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmmDsgLe223f",
        "outputId": "d882e80d-9f6e-4987-e24d-6d8632989918"
      },
      "source": [
        "#Let's look at some reviews and their labels\n",
        "#Train and test datasets are split 50:50 and the examples are in the form of (label, text)\n",
        "\n",
        "for review, label in tfds.as_numpy(ds_train.take(3)):\n",
        "    print('review:', review.decode()[0:150], label)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "review: This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be the 0\n",
            "review: I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable  0\n",
            "review: Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lK2AiuAy3S3j",
        "outputId": "e7c0d1d2-71fa-4e98-ac6e-ef6661f5dbe0"
      },
      "source": [
        "#Apply BERT tokenizer on all the examples - this can be done using encode_plus function.\n",
        "import time\n",
        "t0 = time.time()\n",
        "\n",
        "def map_example_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
        "  return {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"token_type_ids\": token_type_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "  }, label\n",
        "\n",
        "# def convert_example_to_feature(decoded_reviews):\n",
        "#   bert_input = tokenizer.encode_plus(\n",
        "#                         decoded_reviews,                      \n",
        "#                         add_special_tokens = True, # add [CLS], [SEP]\n",
        "#                         max_length = 192, # max length of the text that can go to BERT\n",
        "#                         pad_to_max_length = True, # add [PAD] tokens\n",
        "#                         return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
        "#               )\n",
        "#   return bert_input\n",
        "\n",
        "def convert_example_to_feature(review):\n",
        "  # combine step for tokenization, WordPiece vector mapping and will add also special tokens and truncate reviews longer than our max length\n",
        "  return tokenizer.encode_plus(review, \n",
        "                add_special_tokens = True, # add [CLS], [SEP]\n",
        "                max_length = 128, # max length of the text that can go to BERT\n",
        "                pad_to_max_length = True, # add [PAD] tokens\n",
        "                return_attention_mask = True,# add attention mask to not focus on pad tokens\n",
        "                truncation = True \n",
        "              )\n",
        "  \n",
        "def encode_examples(ds, limit=-1):\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = []\n",
        "  if (limit > 0):\n",
        "      ds = ds.take(limit)\n",
        "    \n",
        "  for review, label in tfds.as_numpy(ds):\n",
        "    bert_input = convert_example_to_feature(review.decode())\n",
        "  \n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "    label_list.append([label])\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "format_time(time.time() - t0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0:00:00'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4nb4PiGa5FVd",
        "outputId": "e86652c9-ffaf-49d7-86a1-6a673342bc43"
      },
      "source": [
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "t0 = time.time()\n",
        "batch_size = 32\n",
        "\n",
        "# train dataset\n",
        "ds_train_encoded = encode_examples(ds_train).shuffle(10000).batch(batch_size)\n",
        "# test dataset\n",
        "ds_test_encoded = encode_examples(ds_test).batch(batch_size)\n",
        "format_time(time.time() - t0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0:05:27'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4qm5Yq35Xjd",
        "outputId": "47fe5478-24e7-4dda-c83f-5bff55601457"
      },
      "source": [
        "from transformers import TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# recommended learning rate for Adam 5e-5, 3e-5, 2e-5\n",
        "learning_rate = 2e-5\n",
        "# we will do just 1 epoch for illustration, though multiple epochs might be better as long as we will not overfit the model\n",
        "number_of_epochs = 1\n",
        "\n",
        "# model initialization\n",
        "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# optimizer Adam recommended\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
        "\n",
        "# we do not have one-hot vectors, we can use sparce categorical cross entropy and accuracy\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRr6IPvW-XO2",
        "outputId": "a9167db0-202b-4209-ce03-e5bf3bf948d9"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "bert_history = model.fit(ds_train_encoded, epochs=number_of_epochs, validation_data=ds_test_encoded)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8118WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r782/782 [==============================] - 306s 373ms/step - loss: 0.4004 - accuracy: 0.8118 - val_loss: 0.2658 - val_accuracy: 0.8883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ciz0QHqrFB2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa949442-262a-41f3-c5d2-f6d764669880"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " EBSCO\t   FoundryShowcase.png\t 'MIDS Resources'  'Shared Items'   W201   W266\n",
            " Finance  'Getting started.pdf'   Presentations     W200\t    W207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPgb6y4rL0on",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1912ed24-f7d3-4ab7-ef3d-864c5dab804e"
      },
      "source": [
        "#load the financial phrasebank\n",
        "import itertools\n",
        "import random\n",
        "s2 = []\n",
        "l2 = []\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/W266/FinancialPhraseBank-v1.0/Sentences_AllAgree.txt', 'r', encoding='cp1252') as f:  \n",
        "  lines = f.readlines()\n",
        "  random.shuffle(lines)\n",
        "  for line in lines:\n",
        "    line_split = line.split('@')\n",
        "    if line_split[-1][:-1] != 'neutral':\n",
        "      s2.append(line_split[:-1])\n",
        "      l2.append(line_split[-1][:-1])    \n",
        "\n",
        "sentences = list(itertools.chain(*s2))\n",
        "labels = []\n",
        "\n",
        "for label in l2:\n",
        "  if label == 'positive':\n",
        "    labels.append(1)\n",
        "  elif label == 'negative':\n",
        "    labels.append(0)\n",
        "\n",
        "\n",
        "\n",
        "print('len of senteces:',len(sentences))\n",
        "print('len of labels:',len(labels))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of senteces: 873\n",
            "len of labels: 873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKsH2sU0OCQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36e06af-bbe0-4059-82e0-6488151c59b0"
      },
      "source": [
        "#Truncate sentences and encode\n",
        "\n",
        "max_len = 150\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "\n",
        "    #let's truncate sequneces to maxlen \n",
        "    if len(sent) > max_len:\n",
        "      sent = sent[:max_len]\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "\n",
        "\n",
        "def encode_sentences(sentences,label, limit=-1):\n",
        "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
        "  input_ids_list = []\n",
        "  token_type_ids_list = []\n",
        "  attention_mask_list = []\n",
        "  label_list = list(label)\n",
        "  if (limit > 0):\n",
        "      ds = ds.take(limit)\n",
        "    \n",
        "  for sent in sentences:\n",
        "    bert_input = convert_example_to_feature(sent)\n",
        "  \n",
        "    input_ids_list.append(bert_input['input_ids'])\n",
        "    token_type_ids_list.append(bert_input['token_type_ids'])\n",
        "    attention_mask_list.append(bert_input['attention_mask'])\n",
        "  #  label_list.append([label])\n",
        "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_example_to_dict)\n",
        "\n",
        "\n",
        "\n",
        "#Financial Phrasebank\n",
        "train_sentences_length = int(0.8*len(sentences))\n",
        "val_sentences_length = int(0.1*len(sentences))\n",
        "test_sentences_length = len(sentences) - train_sentences_length-val_sentences_length\n",
        "\n",
        "#  tf.contrib.training.stratified_sample([data], label, target_probs)\n",
        "\n",
        "\n",
        "x_train = sentences[:train_sentences_length]\n",
        "y_train = labels[:train_sentences_length]\n",
        "\n",
        "x_val = sentences[train_sentences_length:train_sentences_length+val_sentences_length]\n",
        "y_val = labels[train_sentences_length:train_sentences_length+val_sentences_length]\n",
        "\n",
        "x_test = sentences[-test_sentences_length:]\n",
        "y_test = labels[-test_sentences_length:]\n",
        "\n",
        "x_total = sentences\n",
        "y_total = labels\n",
        "\n",
        "print(\"Length of train, val and test: \", len(x_train),len(x_val),len(x_test))\n",
        "print(\"Length of train, val and test: \", train_sentences_length,val_sentences_length,test_sentences_length )\n",
        "\n",
        "print(\"Length of total dataset = \", train_sentences_length+val_sentences_length+test_sentences_length)\n",
        "\n",
        "\n",
        "#Train dataset\n",
        "fin_train_encoded = encode_sentences(x_train,y_train).shuffle(100).batch(batch_size)\n",
        "\n",
        "#Val dataset\n",
        "fin_val_encoded = encode_sentences(x_val, y_val).batch(batch_size)\n",
        "\n",
        "# test dataset\n",
        "fin_test_encoded = encode_sentences(x_test,y_test).batch(batch_size)\n",
        "\n",
        "#Toal dataset \n",
        "fin_total_encoded = encode_sentences(x_total,y_total).batch(batch_size)\n",
        "\n",
        "\n",
        "# x_train[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  150\n",
            "Length of train, val and test:  698 87 88\n",
            "Length of train, val and test:  698 87 88\n",
            "Length of total dataset =  873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqwLcjoJIcbJ",
        "outputId": "cc5cb1c0-f33f-458d-e8d4-d6b61020d1a1"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "class_weights_test = class_weight.compute_class_weight('balanced', np.unique(y_test), y_test)\n",
        "class_weights_train = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "\n",
        "\n",
        "print(\"Train:\",class_weights_train)\n",
        "print(\"Test:\",class_weights_test)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: [1.41869919 0.77212389]\n",
            "Test: [1.62962963 0.72131148]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB_NDyY4gbKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14369e5-caaa-498a-e6e1-5059be7e7449"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
        "\n",
        "class_weight_dict = {0: class_weights[0],\n",
        "                1: class_weights[1]\n",
        "               }\n",
        "\n",
        "bert_history2 = model.fit(fin_train_encoded, class_weight=class_weight_dict , epochs=3, validation_data=fin_val_encoded)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.8782WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r22/22 [==============================] - 17s 399ms/step - loss: 0.3359 - accuracy: 0.8782 - val_loss: 0.0756 - val_accuracy: 0.9770\n",
            "Epoch 2/3\n",
            "22/22 [==============================] - 6s 285ms/step - loss: 0.1021 - accuracy: 0.9670 - val_loss: 0.0754 - val_accuracy: 0.9770\n",
            "Epoch 3/3\n",
            "22/22 [==============================] - 6s 285ms/step - loss: 0.0469 - accuracy: 0.9842 - val_loss: 0.0977 - val_accuracy: 0.9655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXTqmnPOr4Ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc8824fe-aff2-4665-b82f-91ce41bad8f7"
      },
      "source": [
        "print(\"Train Accuracy(%): {:.2f}\".format(model.evaluate(fin_train_encoded, batch_size=None, verbose=1)[1]*100))\n",
        "print(\"Val Accuracy(%): {:.2f}\".format(model.evaluate(fin_val_encoded, batch_size=None, verbose=1)[1]*100))\n",
        "print(\"Test Accuracy(%): {:.2f}\".format(model.evaluate(fin_test_encoded, batch_size=None, verbose=1)[1]*100))\n",
        "print(\"TOTAL Accuracy(%): {:.2f}\".format(model.evaluate(fin_total_encoded, batch_size=None, verbose=1)[1]*100))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 2s 103ms/step - loss: 0.0268 - accuracy: 0.9914\n",
            "Train Accuracy(%): 99.14\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.0977 - accuracy: 0.9655\n",
            "Val Accuracy(%): 96.55\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.1439 - accuracy: 0.9545\n",
            "Test Accuracy(%): 95.45\n",
            "28/28 [==============================] - 3s 102ms/step - loss: 0.0457 - accuracy: 0.9851\n",
            "TOTAL Accuracy(%): 98.51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGjW8K7wxriR"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}