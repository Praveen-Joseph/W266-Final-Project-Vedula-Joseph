{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w266_final_project_final_FinSen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1e52311298e24c51a8720889842342c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c9345ac98954c9883d0bc9ba89a5e71",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40b23fd6390a4d829643f2bab7f159c0",
              "IPY_MODEL_49e3b78f59bf46de8b94eefdaca4b3c2"
            ]
          }
        },
        "6c9345ac98954c9883d0bc9ba89a5e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40b23fd6390a4d829643f2bab7f159c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cdb2b267966044b0aa041c5f3576cf74",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_784a004d844b417b9db5cfcb8db5ea73"
          }
        },
        "49e3b78f59bf46de8b94eefdaca4b3c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_42e922f86b9144ab99cdfb1854b19fd7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 820kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17f0fb11d87341468e77fbe00ddd6155"
          }
        },
        "cdb2b267966044b0aa041c5f3576cf74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "784a004d844b417b9db5cfcb8db5ea73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42e922f86b9144ab99cdfb1854b19fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17f0fb11d87341468e77fbe00ddd6155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "650500fedc874d6dabad1fbaa843ab6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4314744fb19a47bfa65965d7800a4c67",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df768a3e24b8478e8002a58fccafc57b",
              "IPY_MODEL_c50a4f412dc54748a8a48d33ef02e6d8"
            ]
          }
        },
        "4314744fb19a47bfa65965d7800a4c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df768a3e24b8478e8002a58fccafc57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5e76231707047a38e8c8d7d90c0c7c8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f78bf3193be94dc3bf49c7f250299f50"
          }
        },
        "c50a4f412dc54748a8a48d33ef02e6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc39d4f624914181955bb8fb6a4545e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 101B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfa4b485de5a4421a50686ffc66375a0"
          }
        },
        "f5e76231707047a38e8c8d7d90c0c7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f78bf3193be94dc3bf49c7f250299f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc39d4f624914181955bb8fb6a4545e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfa4b485de5a4421a50686ffc66375a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6366332754d64851b639465bd4d0ff00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3cf74ebbe0a49d3866484fb963ee41f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6852642e78424c159a064d0fa8cd3f95",
              "IPY_MODEL_5ee9668c608c44d98d43da9a738911bf"
            ]
          }
        },
        "a3cf74ebbe0a49d3866484fb963ee41f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6852642e78424c159a064d0fa8cd3f95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b49d0a730e14f33befae92fba4bf837",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee809ad2aedb46519947f173b27c505e"
          }
        },
        "5ee9668c608c44d98d43da9a738911bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6842270340846faa742cbe747dc0fc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 3.95MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37d1920dfd3c47519c7326316d4f9399"
          }
        },
        "7b49d0a730e14f33befae92fba4bf837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee809ad2aedb46519947f173b27c505e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6842270340846faa742cbe747dc0fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37d1920dfd3c47519c7326316d4f9399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48e5005ab837439d9732da80974fc05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_492bb972530348e28a77e7d995045dfa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a01895efbfed42e09fa0aa0e1c850688",
              "IPY_MODEL_aeb97c5968324066b295cff798e18c66"
            ]
          }
        },
        "492bb972530348e28a77e7d995045dfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a01895efbfed42e09fa0aa0e1c850688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9bf4ef012a5b4d86bc07d224e2ecb5c3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_669155fae81f46f79cff721ad8d2d052"
          }
        },
        "aeb97c5968324066b295cff798e18c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5d593bc96c874437ac9a5256a72dee3e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:12&lt;00:00, 36.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d8e2ff025c5499ea8faf6d51f396624"
          }
        },
        "9bf4ef012a5b4d86bc07d224e2ecb5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "669155fae81f46f79cff721ad8d2d052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d593bc96c874437ac9a5256a72dee3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d8e2ff025c5499ea8faf6d51f396624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4ba316b526d4555975b7e25a4be9763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc8b118000eb49bbb05a8b5514410c18",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca1b09271bf1417fb6092aa6249fda52",
              "IPY_MODEL_0fce67d4ddc54f679052459507a2d084"
            ]
          }
        },
        "cc8b118000eb49bbb05a8b5514410c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca1b09271bf1417fb6092aa6249fda52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f820d6d3502d49a1bd84b1b7760942e9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_850ad28dfecc4dbb918cb198c247a666"
          }
        },
        "0fce67d4ddc54f679052459507a2d084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ae1d0ab2978479db7d681063c5f5422",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:11&lt;00:00, 37.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44572203bfa14d19b45e4791b1b8824d"
          }
        },
        "f820d6d3502d49a1bd84b1b7760942e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "850ad28dfecc4dbb918cb198c247a666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ae1d0ab2978479db7d681063c5f5422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44572203bfa14d19b45e4791b1b8824d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlFhJKhJg_AH"
      },
      "source": [
        "## Specify key parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyHpuRwelupC"
      },
      "source": [
        "# parameters\n",
        "# use num_labels = 3 if using positive for 0, negative for 1, neutral for 2\n",
        "# use num_labels = 2 if using positive for 0, negative for 1\n",
        "num_labels = 2\n",
        "\n",
        "# input file name from financial phrasebank data\n",
        "filename = 'Sentences_50Agree.txt'\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, For fine-tuning \n",
        "# BERT on a specific task, Devlin et. al. recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# maximum sequence length. use EDA and look at results to set this parameter\n",
        "max_seq_length = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_aUMbn7WDHo",
        "outputId": "c73cd74f-378d-429a-803e-2f8fcc5026dd"
      },
      "source": [
        "!pip install transformers\n",
        "# !pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/91/61d69d58a1af1bd81d9ca9d62c90a6de3ab80d77f27c5df65d9a2c1f5626/transformers-4.5.0-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2MB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 870kB 22.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=e76241d83d3f1e69b4015852460614c617ed5be8dfb5f2ba4386a732f08d80b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.10.2 transformers-4.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btxoYQdQVVpu"
      },
      "source": [
        "# import modules\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import wget\n",
        "import os\n",
        "import itertools\n",
        "import collections\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler, ConcatDataset\n",
        "from torchvision import transforms, utils, datasets\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8b5f79-261e-43df-d559-4e9b637b3f26"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "# If a GPU is available\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If no GPU is available\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttkW8VZmPvjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06eb7ba-1162-4dc1-b9ee-1b2576b7eb8d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79Zk93uhJmb"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v_icb1iRAeC"
      },
      "source": [
        "# function to read in filename and create a list with sentences and a list with labels\n",
        "# these are then used to create pandas dataframe for train and test data. \n",
        "\n",
        "def read_data(filename, num_labels):\n",
        "\n",
        "  s2_train = []\n",
        "  l2_train = []\n",
        "  s2_test = []\n",
        "  l2_test = []\n",
        "\n",
        "  s3_train = []\n",
        "  l3_train = []\n",
        "  s3_test = []\n",
        "  l3_test = []\n",
        "\n",
        "  fname = '/content/drive/My Drive/data/' + filename \n",
        "  with open(fname, 'r', encoding='cp1252') as f:  \n",
        "    lines = f.readlines()\n",
        "    random.shuffle(lines)\n",
        "\n",
        "    split_ratio = 0.9 # 90% data used for train and dev, 10% is held-out\n",
        "    train_size = int(split_ratio * len(lines))\n",
        "    test_size = len(lines) - train_size\n",
        "\n",
        "    lines_train = random.sample(lines, train_size)\n",
        "    lines_test = list((collections.Counter(lines)-collections.Counter(lines_train)).elements())\n",
        "\n",
        "    if num_labels == 2:\n",
        "      for line in lines_train:\n",
        "        line_split = line.split('@')\n",
        "        if line_split[-1][:-1] != 'neutral':\n",
        "          s2_train.append(line_split[:-1])\n",
        "          l2_train.append(line_split[-1][:-1])    \n",
        "\n",
        "      for line in lines_test:\n",
        "        line_split = line.split('@')\n",
        "        if line_split[-1][:-1] != 'neutral':\n",
        "          s2_test.append(line_split[:-1])\n",
        "          l2_test.append(line_split[-1][:-1])    \n",
        "\n",
        "      sentences_train = list(itertools.chain(*s2_train))\n",
        "      labels_train = []\n",
        "\n",
        "      sentences_test = list(itertools.chain(*s2_test))\n",
        "      labels_test = []\n",
        "\n",
        "      for label in l2_train:\n",
        "        if label == 'positive':\n",
        "          labels_train.append(0)\n",
        "        elif label == 'negative':\n",
        "          labels_train.append(1)\n",
        "\n",
        "      for label in l2_test:\n",
        "        if label == 'positive':\n",
        "          labels_test.append(0)\n",
        "        elif label == 'negative':\n",
        "          labels_test.append(1)\n",
        "\n",
        "      df_train = pd.DataFrame(list(zip(sentences_train, labels_train)),\n",
        "                              columns=['sentences_train', 'labels_train'])\n",
        "\n",
        "      df_test = pd.DataFrame(list(zip(sentences_test, labels_test)),\n",
        "                             columns=['sentences_test', 'labels_test'])\n",
        " \n",
        "    elif num_labels == 3:\n",
        "      for line in lines_train:\n",
        "        line_split = line.split('@')\n",
        "        s3_train.append(line_split[:-1])\n",
        "        l3_train.append(line_split[-1][:-1])    \n",
        "\n",
        "      for line in lines_test:\n",
        "        line_split = line.split('@')\n",
        "        s3_test.append(line_split[:-1])\n",
        "        l3_test.append(line_split[-1][:-1])\n",
        "\n",
        "      sentences_train = list(itertools.chain(*s3_train))\n",
        "      labels_train = []\n",
        "\n",
        "      sentences_test = list(itertools.chain(*s3_test))\n",
        "      labels_test = []\n",
        "\n",
        "      for label in l3_train:\n",
        "        if label == 'positive':\n",
        "          labels_train.append(0)\n",
        "        elif label == 'negative':\n",
        "          labels_train.append(1)\n",
        "        elif label == 'neutral':\n",
        "          labels_train.append(2)\n",
        "\n",
        "      for label in l3_test:\n",
        "        if label == 'positive':\n",
        "          labels_test.append(0)\n",
        "        elif label == 'negative':\n",
        "          labels_test.append(1)\n",
        "        elif label == 'neutral':\n",
        "          labels_test.append(2)\n",
        "\n",
        "      df_train = pd.DataFrame(list(zip(sentences_train, labels_train)),\n",
        "                              columns=['sentences_train', 'labels_train'])\n",
        "\n",
        "      df_test = pd.DataFrame(list(zip(sentences_test, labels_test)),\n",
        "                             columns=['sentences_test', 'labels_test'])\n",
        "\n",
        "  return df_train, df_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V1nqwx1b6_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "1e52311298e24c51a8720889842342c1",
            "6c9345ac98954c9883d0bc9ba89a5e71",
            "40b23fd6390a4d829643f2bab7f159c0",
            "49e3b78f59bf46de8b94eefdaca4b3c2",
            "cdb2b267966044b0aa041c5f3576cf74",
            "784a004d844b417b9db5cfcb8db5ea73",
            "42e922f86b9144ab99cdfb1854b19fd7",
            "17f0fb11d87341468e77fbe00ddd6155",
            "650500fedc874d6dabad1fbaa843ab6c",
            "4314744fb19a47bfa65965d7800a4c67",
            "df768a3e24b8478e8002a58fccafc57b",
            "c50a4f412dc54748a8a48d33ef02e6d8",
            "f5e76231707047a38e8c8d7d90c0c7c8",
            "f78bf3193be94dc3bf49c7f250299f50",
            "cc39d4f624914181955bb8fb6a4545e5",
            "bfa4b485de5a4421a50686ffc66375a0",
            "6366332754d64851b639465bd4d0ff00",
            "a3cf74ebbe0a49d3866484fb963ee41f",
            "6852642e78424c159a064d0fa8cd3f95",
            "5ee9668c608c44d98d43da9a738911bf",
            "7b49d0a730e14f33befae92fba4bf837",
            "ee809ad2aedb46519947f173b27c505e",
            "a6842270340846faa742cbe747dc0fc8",
            "37d1920dfd3c47519c7326316d4f9399"
          ]
        },
        "outputId": "dc9a7761-689b-461a-e790-a0cdfda3bbd4"
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e52311298e24c51a8720889842342c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "650500fedc874d6dabad1fbaa843ab6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6366332754d64851b639465bd4d0ff00",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUC_gMNp3LRg"
      },
      "source": [
        "# calculate the max number of tokens in a sentence. \n",
        "def get_max_length(df):\n",
        "\n",
        "  max_len = 0\n",
        "  # For every sentence\n",
        "  for sent in df['sentences_train']:\n",
        "\n",
        "      # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "      input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "      # Update the maximum sentence length.\n",
        "      max_len = max(max_len, len(input_ids))\n",
        "\n",
        "  return max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJwUpqb3lvc-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6a35fff-8e7b-46e3-a97f-57dcc3f2a459"
      },
      "source": [
        "# create train and test datasets\n",
        "df_train, df_test = read_data(filename, num_labels)\n",
        "\n",
        "sentences_train, labels_train = df_train['sentences_train'], df_train['labels_train']\n",
        "sentences_test, labels_test = df_test['sentences_test'], df_test['labels_test']\n",
        "\n",
        "print('number of train examples:', len(sentences_train) )\n",
        "print('number of test examples:', len(sentences_test) )\n",
        "\n",
        "if num_labels == 2:\n",
        "  print('pos_train', len(df_train[df_train['labels_train']==0]))\n",
        "  print('neg_train', len(df_train[df_train['labels_train']==1]))\n",
        "  print('pos_test', len(df_test[df_test['labels_test']==0]))\n",
        "  print('neg_test', len(df_test[df_test['labels_test']==1]))\n",
        "\n",
        "elif num_labels == 3:\n",
        "  print('pos_train', len(df_train[df_train['labels_train']==0]))\n",
        "  print('neg_train', len(df_train[df_train['labels_train']==1]))\n",
        "  print('neu_train', len(df_train[df_train['labels_train']==2]))\n",
        "  print('pos_test', len(df_test[df_test['labels_test']==0]))\n",
        "  print('neg_test', len(df_test[df_test['labels_test']==1]))\n",
        "  print('neu_test', len(df_test[df_test['labels_test']==2]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train examples: 1767\n",
            "number of test examples: 200\n",
            "pos_train 1213\n",
            "neg_train 554\n",
            "pos_test 150\n",
            "neg_test 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwmIX8kH6b6Y"
      },
      "source": [
        "# max_len_train = get_max_length(df_train)\n",
        "# max_len_test = get_max_length(df_test)\n",
        "\n",
        "# print('Max sentence length: ', max_len_train, max_len_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "DWSgkkDZBPgp",
        "outputId": "4af160c3-f25a-4b43-868a-cee692f83ece"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences_train</th>\n",
              "      <th>labels_train</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The steelmaker said that the drop in profit wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Finnish Bank of +Ã land 's consolidated net ope...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The agreement will provide The Switch with dou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sales of clothing developed best .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The executive group will participate in the ad...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1762</th>\n",
              "      <td>The production is to be liquidated before June...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1763</th>\n",
              "      <td>Possible personnel reductions concern approxim...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1764</th>\n",
              "      <td>Previously , the company had guided for EBIT a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1765</th>\n",
              "      <td>`` Our extensive co-operation will also bolste...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1766</th>\n",
              "      <td>UPM-Kymmene has generated thirty-one consecuti...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1767 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentences_train  labels_train\n",
              "0     The steelmaker said that the drop in profit wa...             1\n",
              "1     Finnish Bank of +Ã land 's consolidated net ope...             0\n",
              "2     The agreement will provide The Switch with dou...             0\n",
              "3                    Sales of clothing developed best .             0\n",
              "4     The executive group will participate in the ad...             0\n",
              "...                                                 ...           ...\n",
              "1762  The production is to be liquidated before June...             1\n",
              "1763  Possible personnel reductions concern approxim...             1\n",
              "1764  Previously , the company had guided for EBIT a...             0\n",
              "1765  `` Our extensive co-operation will also bolste...             0\n",
              "1766  UPM-Kymmene has generated thirty-one consecuti...             0\n",
              "\n",
              "[1767 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014ad98c-3de7-49c3-e1a7-5d4d5a8e9d82"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  The steelmaker said that the drop in profit was explained by the continuing economic uncertainty , mixed with the current drought in bank lending , resulting in a decline in demand for its products as customers find it increasingly difficult to fund operations .\n",
            "Tokenized:  ['the', 'steel', '##maker', 'said', 'that', 'the', 'drop', 'in', 'profit', 'was', 'explained', 'by', 'the', 'continuing', 'economic', 'uncertainty', ',', 'mixed', 'with', 'the', 'current', 'drought', 'in', 'bank', 'lending', ',', 'resulting', 'in', 'a', 'decline', 'in', 'demand', 'for', 'its', 'products', 'as', 'customers', 'find', 'it', 'increasingly', 'difficult', 'to', 'fund', 'operations', '.']\n",
            "Token IDs:  [1996, 3886, 8571, 2056, 2008, 1996, 4530, 1999, 5618, 2001, 4541, 2011, 1996, 5719, 3171, 12503, 1010, 3816, 2007, 1996, 2783, 14734, 1999, 2924, 18435, 1010, 4525, 1999, 1037, 6689, 1999, 5157, 2005, 2049, 3688, 2004, 6304, 2424, 2009, 6233, 3697, 2000, 4636, 3136, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19dfe1f3-08e4-4fad-e7d9-0918c2faec70"
      },
      "source": [
        "## Motivated by Chris McCormick's tutorial: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# loop over sentences\n",
        "for sent in sentences_train:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                           # Sentence to encode.\n",
        "                        add_special_tokens = True,      # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_seq_length,               # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',          # Return pytorch tensors.\n",
        "                  )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (0 for padding and 1 for non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels_train)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences_train[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  The steelmaker said that the drop in profit was explained by the continuing economic uncertainty , mixed with the current drought in bank lending , resulting in a decline in demand for its products as customers find it increasingly difficult to fund operations .\n",
            "Token IDs: tensor([  101,  1996,  3886,  8571,  2056,  2008,  1996,  4530,  1999,  5618,\n",
            "         2001,  4541,  2011,  1996,  5719,  3171, 12503,  1010,  3816,  2007,\n",
            "         1996,  2783, 14734,  1999,  2924, 18435,  1010,  4525,  1999,  1037,\n",
            "         6689,  1999,  5157,  2005,  2049,  3688,  2004,  6304,  2424,  2009,\n",
            "         6233,  3697,  2000,  4636,  3136,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4d85c5-6dea-42fc-db1f-0cb57e4da916"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 split of train into train and dev. use cross-dev later\n",
        "data_size = len(dataset)\n",
        "train_size = int(0.9 * data_size)\n",
        "dev_size = data_size - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, dev_dataset = random_split(dataset, [train_size, dev_size])\n",
        "\n",
        "print('{:>5,} train samples'.format(train_size))\n",
        "print('{:>5,} dev samples'.format(dev_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,590 train samples\n",
            "  177 dev samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "# Create the DataLoaders for our training and dev sets. We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "\n",
        "# For dev order doesn't matter, so we'll just read them sequentially.\n",
        "dev_dataloader = DataLoader(dev_dataset, sampler=SequentialSampler(dev_dataset), batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvxeoFO_hSZ-"
      },
      "source": [
        "# Model set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48e5005ab837439d9732da80974fc05e",
            "492bb972530348e28a77e7d995045dfa",
            "a01895efbfed42e09fa0aa0e1c850688",
            "aeb97c5968324066b295cff798e18c66",
            "9bf4ef012a5b4d86bc07d224e2ecb5c3",
            "669155fae81f46f79cff721ad8d2d052",
            "5d593bc96c874437ac9a5256a72dee3e",
            "5d8e2ff025c5499ea8faf6d51f396624",
            "d4ba316b526d4555975b7e25a4be9763",
            "cc8b118000eb49bbb05a8b5514410c18",
            "ca1b09271bf1417fb6092aa6249fda52",
            "0fce67d4ddc54f679052459507a2d084",
            "f820d6d3502d49a1bd84b1b7760942e9",
            "850ad28dfecc4dbb918cb198c247a666",
            "2ae1d0ab2978479db7d681063c5f5422",
            "44572203bfa14d19b45e4791b1b8824d"
          ]
        },
        "outputId": "fdc1e7ec-e1ab-423c-c1ce-c58fa97ed1fa"
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "# num_labels = 2 if positive, negative\n",
        "# num_labels = 3 if positive, negative, neutral\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                      num_labels = num_labels, # number of classes\n",
        "                                                      output_attentions = False, \n",
        "                                                      output_hidden_states = False, \n",
        "                                                     )\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48e5005ab837439d9732da80974fc05e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ba316b526d4555975b7e25a4be9763",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9547639-eb75-47c7-f703-14293ff7a140"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. higher epochs may over-fit the training data.\n",
        "epochs = 4\n",
        "\n",
        "# number of training steps is [number of batches] x [number of epochs]. \n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqkkMnzHwQ8t"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    # Takes a time in seconds and returns a string hh:mm:ss. Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_JHHcyYYY0M"
      },
      "source": [
        "# Function to calculate the accuracy\n",
        "def my_metrics(preds, labels, num_labels):\n",
        "\n",
        "    y_pred = np.argmax(preds, axis=1).flatten()\n",
        "    y_true = labels.flatten()\n",
        "    accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KmzTInRhaK_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vTRrWTTfhJfO",
        "outputId": "706fbe9a-3e9e-48f6-bf9a-e8cddddb07da"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and dev loss, \n",
        "# dev accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. \n",
        "    model.train()\n",
        "\n",
        "    # loop over each batch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack training batch from dataloader and copy each tensor to the GPU \n",
        "        # using the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function returns the value from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               dev\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, check dev metrics\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running dev...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        # Unpack batch from dataloader and copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to construct the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the dev loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        y_pred = np.argmax(logits, axis=1).flatten()\n",
        "        y_true = label_ids.flatten()\n",
        "\n",
        "        print(classification_report(y_true, y_pred))\n",
        "        print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "        d = {}\n",
        "        for i in range(len(label_ids)):\n",
        "          # x is actual label, y is predicted label\n",
        "          x = label_ids[i]\n",
        "          y = np.argmax(logits, axis=1).flatten()[i]\n",
        "          z = tokenizer.convert_ids_to_tokens(b_input_ids[i])\n",
        "          merged = list(itertools.chain(*z))\n",
        "          d[i] = ' '.join(merged)\n",
        "          \n",
        "          print('sentence', d[i], '\\n')\n",
        "          print('true label, pred label', x, y)\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "\n",
        "        total_eval_accuracy += my_metrics(logits, label_ids, num_labels)\n",
        "\n",
        "    # Report the final accuracy for this dev run.\n",
        "    n_dev = len(dev_dataloader)\n",
        "\n",
        "    avg_dev_accuracy = total_eval_accuracy / n_dev\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_dev_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_dev_loss = total_eval_loss / n_dev\n",
        "    \n",
        "    # Measure how long the dev run took.\n",
        "    dev_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  dev loss: {0:.4f}\".format(avg_dev_loss))\n",
        "    print(\"  dev took: {:}\".format(dev_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'train loss': avg_train_loss,\n",
        "            'dev loss': avg_dev_loss,\n",
        "            'dev Accur.': avg_dev_accuracy,\n",
        "            'train Time': training_time,\n",
        "            'dev Time': dev_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     50.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.4687\n",
            "  Training epoch took: 0:00:20\n",
            "\n",
            "Running Validation...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        24\n",
            "           1       0.80      1.00      0.89         8\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.90      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[22  2]\n",
            " [ 0  8]]\n",
            "sentence [ C L S ] t h e c o m p a n y s t i l l e x p e c t s i t s t u r n o v e r i n 2 0 1 0 t o s l i g h t l y i n c r e a s e f r o m t h e l e v e l o f 2 0 0 9 , a d d i n g t h a t ` ` m a r k e t p r e d i c t # # a b i l i t y i s s t i l l t o o p o o r f o r t r u s t # # w o r t h y f o r e c a s t # # s o n t h e m a r k e t d e v e l o p m e n t o f t h e c o n t r a c t m a n u f a c t u r i n g b u s i n e s s d u r i n g t h e c u r r e n t y e a r ' ' . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] l o s s a f t e r t a x e s a m o u n t e d t o e u # # r 1 . 2 m n c o m p a r e d t o a l o s s o f 2 . 6 m n . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 22\n",
            "neg_neg 8\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 2\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        25\n",
            "           1       0.78      1.00      0.88         7\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.89      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[23  2]\n",
            " [ 0  7]]\n",
            "sentence [ C L S ] t h e s t o c k p r i c e r o s e 7 0 . 0 o r e # # s o r 0 . 9 % t o c l o s e a t s e # # k # # 7 # # 7 . 6 5 , e n d i n g a t w o - d a y s t r e a k o f l o s s e s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] k e y s h a r e h o l d e r s o f f i n n i s h i t s e r v i c e s p r o v i d e r t i e # # t o # # e n a # # t o r o # # y # # j o n f r i d a y r e j e c t e d a h o s t i l e e u # # r # # 1 . 0 8 b i l l i o n $ 1 . 6 7 b i l l i o n o f f e r f r o m b u y # # o u t s h o p n o r d i c c a p i t a l , g i v i n g n e w l i f e t o a p o s s i b l e c o u n t e r o f f e r f r o m b l a c k s # # t o n e g r o u p l p a n d n o r w e g i a n t e l e c o m t e l # # e n o # # r a s a . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 45\n",
            "neg_neg 15\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 4\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.85      0.90        26\n",
            "           1       0.56      0.83      0.67         6\n",
            "\n",
            "    accuracy                           0.84        32\n",
            "   macro avg       0.76      0.84      0.78        32\n",
            "weighted avg       0.88      0.84      0.85        32\n",
            "\n",
            "[[22  4]\n",
            " [ 1  5]]\n",
            "sentence [ C L S ] n o k i a w a s u p 0 . 1 2 p c # # t t o 1 6 . 7 0 e u # # r a f t e r k i c k i n g o f f t h e m o r n i n g i n n e g a t i v e t e r r i t o r y . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] c o s t c u t t i n g m e a s u r e s , w h i c h h a v e p r o d u c e d a r o u n d e u # # r # # 7 0 # # m o f s a v i n g s o v e r t h e p a s t n i n e m o n t h s , h a v e d a m p # # e n e d t h e a i r l i n e ' s l o s s , f i n n # # a i r s a i d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] i n t h e f i r s t n i n e m o n t h s o f 2 0 1 0 , t h e c o m p a n y ' s n e t l o s s n a r r o w e d t o e u # # r # # 4 1 # # 5 , 0 0 0 f r o m e u # # r # # 7 . 4 m f o r t h e c o r r e s p o n d i n g p e r i o d o f 2 0 0 9 . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] f i n n i s h m e t a l p r o d u c t s c o m p a n y c o m p o n e n t # # a o # # y # # j ( h e # # l : c t # # h # # 1 # # v ) s a i d t o d a y i t s n e t l o s s n a r r o w e d t o e u # # r 5 0 0 , 0 0 0 ( u s d 6 8 0 , 0 0 0 ) i n t h e l a s t q u a r t e r o f 2 0 1 0 f r o m e u # # r 5 . 3 m i l l i o n f o r t h e s a m e p e r i o d a y e a r e a r l i e r . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] r a w m a t e r i a l s p r i c e s h a v e s u r g e d i n t h e p a s t y e a r , f u e l e d i n p a r t b e c a u s e o f t h e r a p i d i n d u s t r i a l # # i z a t i o n o f c h i n a , i n d i a a n d o t h e r d e v e l o p i n g n a t i o n s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 67\n",
            "neg_neg 20\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 8\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.98        22\n",
            "           1       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.95      0.98      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "[[21  1]\n",
            " [ 0 10]]\n",
            "sentence [ C L S ] f o r t h e f i r s t n i n e m o n t h s o f 2 0 1 0 , t a l # # v i # # v a # # a r a ' s n e t l o s s n a r r o w e d t o e u # # r 8 . 3 m i l l i o n f r o m e u # # r 2 1 . 9 m i l l i o n f o r t h e s a m e p e r i o d o f 2 0 0 9 . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 88\n",
            "neg_neg 30\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 9\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        23\n",
            "           1       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.95      0.98      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "[[22  1]\n",
            " [ 0  9]]\n",
            "sentence [ C L S ] n e t s a l e s w e n t u p b y 1 % y e a r - o n - y e a r t o e u # # r 2 9 m i l l i o n , a f f e c t e d b y t h e b u s i n e s s a c q u i s i t i o n s , r e a l i z e d d u r i n g t h e p r e v i o u s f i n a n c i a l p e r i o d , t h e e f f e c t o f w h i c h w a s e u # # r 5 . 1 m i l l i o n o n t h e r e v i e w p e r i o d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 110\n",
            "neg_neg 39\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 10\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        17\n",
            "   macro avg       1.00      1.00      1.00        17\n",
            "weighted avg       1.00      1.00      1.00        17\n",
            "\n",
            "[[13  0]\n",
            " [ 0  4]]\n",
            "pos_pos 123\n",
            "neg_neg 43\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 10\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "len dataloader 6\n",
            "  Accuracy: 0.94\n",
            "  avg my accuracy 0.94\n",
            "  Validation Loss: 0.1824\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     50.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.1326\n",
            "  Training epoch took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        24\n",
            "           1       0.80      1.00      0.89         8\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.90      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[22  2]\n",
            " [ 0  8]]\n",
            "sentence [ C L S ] t h e c o m p a n y s t i l l e x p e c t s i t s t u r n o v e r i n 2 0 1 0 t o s l i g h t l y i n c r e a s e f r o m t h e l e v e l o f 2 0 0 9 , a d d i n g t h a t ` ` m a r k e t p r e d i c t # # a b i l i t y i s s t i l l t o o p o o r f o r t r u s t # # w o r t h y f o r e c a s t # # s o n t h e m a r k e t d e v e l o p m e n t o f t h e c o n t r a c t m a n u f a c t u r i n g b u s i n e s s d u r i n g t h e c u r r e n t y e a r ' ' . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] l o s s a f t e r t a x e s a m o u n t e d t o e u # # r 1 . 2 m n c o m p a r e d t o a l o s s o f 2 . 6 m n . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 22\n",
            "neg_neg 8\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 2\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        25\n",
            "           1       0.75      0.86      0.80         7\n",
            "\n",
            "    accuracy                           0.91        32\n",
            "   macro avg       0.85      0.89      0.87        32\n",
            "weighted avg       0.91      0.91      0.91        32\n",
            "\n",
            "[[23  2]\n",
            " [ 1  6]]\n",
            "sentence [ C L S ] t h e s t o c k p r i c e r o s e 7 0 . 0 o r e # # s o r 0 . 9 % t o c l o s e a t s e # # k # # 7 # # 7 . 6 5 , e n d i n g a t w o - d a y s t r e a k o f l o s s e s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] k e y s h a r e h o l d e r s o f f i n n i s h i t s e r v i c e s p r o v i d e r t i e # # t o # # e n a # # t o r o # # y # # j o n f r i d a y r e j e c t e d a h o s t i l e e u # # r # # 1 . 0 8 b i l l i o n $ 1 . 6 7 b i l l i o n o f f e r f r o m b u y # # o u t s h o p n o r d i c c a p i t a l , g i v i n g n e w l i f e t o a p o s s i b l e c o u n t e r o f f e r f r o m b l a c k s # # t o n e g r o u p l p a n d n o r w e g i a n t e l e c o m t e l # # e n o # # r a s a . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] a s p a r t o f t h e r e o r g a n i s a t i o n m e a s u r e s t h a t w i l l t a k e p l a c e i n s p r i n g 2 0 0 6 , t a m # # g l a s s f i n # # t o n w i l l s t a r t p e r s o n n e l n e g o t i a t i o n s t h a t w i l l a f f e c t i t s e n t i r e s t a f f o f 3 3 . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 45\n",
            "neg_neg 14\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 4\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.91        32\n",
            "   macro avg       0.84      0.88      0.86        32\n",
            "weighted avg       0.91      0.91      0.91        32\n",
            "\n",
            "[[24  2]\n",
            " [ 1  5]]\n",
            "sentence [ C L S ] n o k i a w a s u p 0 . 1 2 p c # # t t o 1 6 . 7 0 e u # # r a f t e r k i c k i n g o f f t h e m o r n i n g i n n e g a t i v e t e r r i t o r y . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] c o s t c u t t i n g m e a s u r e s , w h i c h h a v e p r o d u c e d a r o u n d e u # # r # # 7 0 # # m o f s a v i n g s o v e r t h e p a s t n i n e m o n t h s , h a v e d a m p # # e n e d t h e a i r l i n e ' s l o s s , f i n n # # a i r s a i d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] r a w m a t e r i a l s p r i c e s h a v e s u r g e d i n t h e p a s t y e a r , f u e l e d i n p a r t b e c a u s e o f t h e r a p i d i n d u s t r i a l # # i z a t i o n o f c h i n a , i n d i a a n d o t h e r d e v e l o p i n g n a t i o n s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 69\n",
            "neg_neg 19\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 2\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        22\n",
            "           1       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.98      0.95      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "[[22  0]\n",
            " [ 1  9]]\n",
            "sentence [ C L S ] m a k i n g m a t t e r s m o r e d i f f i c u l t , t h e c o m p a n y s a i d i t h a s b e e n g r # # a p p # # l i n g w i t h h i g h e r o i l a n d g a s p r i c e s , w h i c h h a v e p u s h e d u p t h e c o s t o f e n e r g y , r a w m a t e r i a l s a n d t r a n s p o r t a t i o n . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 91\n",
            "neg_neg 28\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 3\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        23\n",
            "           1       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "[[23  0]\n",
            " [ 0  9]]\n",
            "pos_pos 114\n",
            "neg_neg 37\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 3\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        17\n",
            "   macro avg       1.00      1.00      1.00        17\n",
            "weighted avg       1.00      1.00      1.00        17\n",
            "\n",
            "[[13  0]\n",
            " [ 0  4]]\n",
            "pos_pos 127\n",
            "neg_neg 41\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 3\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "len dataloader 6\n",
            "  Accuracy: 0.95\n",
            "  avg my accuracy 0.95\n",
            "  Validation Loss: 0.1409\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     50.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.0715\n",
            "  Training epoch took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        24\n",
            "           1       0.80      1.00      0.89         8\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.90      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[22  2]\n",
            " [ 0  8]]\n",
            "sentence [ C L S ] t h e c o m p a n y s t i l l e x p e c t s i t s t u r n o v e r i n 2 0 1 0 t o s l i g h t l y i n c r e a s e f r o m t h e l e v e l o f 2 0 0 9 , a d d i n g t h a t ` ` m a r k e t p r e d i c t # # a b i l i t y i s s t i l l t o o p o o r f o r t r u s t # # w o r t h y f o r e c a s t # # s o n t h e m a r k e t d e v e l o p m e n t o f t h e c o n t r a c t m a n u f a c t u r i n g b u s i n e s s d u r i n g t h e c u r r e n t y e a r ' ' . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] l o s s a f t e r t a x e s a m o u n t e d t o e u # # r 1 . 2 m n c o m p a r e d t o a l o s s o f 2 . 6 m n . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 22\n",
            "neg_neg 8\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 2\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        25\n",
            "           1       0.78      1.00      0.88         7\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.89      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[23  2]\n",
            " [ 0  7]]\n",
            "sentence [ C L S ] t h e s t o c k p r i c e r o s e 7 0 . 0 o r e # # s o r 0 . 9 % t o c l o s e a t s e # # k # # 7 # # 7 . 6 5 , e n d i n g a t w o - d a y s t r e a k o f l o s s e s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] k e y s h a r e h o l d e r s o f f i n n i s h i t s e r v i c e s p r o v i d e r t i e # # t o # # e n a # # t o r o # # y # # j o n f r i d a y r e j e c t e d a h o s t i l e e u # # r # # 1 . 0 8 b i l l i o n $ 1 . 6 7 b i l l i o n o f f e r f r o m b u y # # o u t s h o p n o r d i c c a p i t a l , g i v i n g n e w l i f e t o a p o s s i b l e c o u n t e r o f f e r f r o m b l a c k s # # t o n e g r o u p l p a n d n o r w e g i a n t e l e c o m t e l # # e n o # # r a s a . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 45\n",
            "neg_neg 15\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 4\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.91        32\n",
            "   macro avg       0.84      0.88      0.86        32\n",
            "weighted avg       0.91      0.91      0.91        32\n",
            "\n",
            "[[24  2]\n",
            " [ 1  5]]\n",
            "sentence [ C L S ] n o k i a w a s u p 0 . 1 2 p c # # t t o 1 6 . 7 0 e u # # r a f t e r k i c k i n g o f f t h e m o r n i n g i n n e g a t i v e t e r r i t o r y . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] c o s t c u t t i n g m e a s u r e s , w h i c h h a v e p r o d u c e d a r o u n d e u # # r # # 7 0 # # m o f s a v i n g s o v e r t h e p a s t n i n e m o n t h s , h a v e d a m p # # e n e d t h e a i r l i n e ' s l o s s , f i n n # # a i r s a i d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] r a w m a t e r i a l s p r i c e s h a v e s u r g e d i n t h e p a s t y e a r , f u e l e d i n p a r t b e c a u s e o f t h e r a p i d i n d u s t r i a l # # i z a t i o n o f c h i n a , i n d i a a n d o t h e r d e v e l o p i n g n a t i o n s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 69\n",
            "neg_neg 20\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        22\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "[[22  0]\n",
            " [ 0 10]]\n",
            "pos_pos 91\n",
            "neg_neg 30\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        23\n",
            "           1       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.95      0.98      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "[[22  1]\n",
            " [ 0  9]]\n",
            "sentence [ C L S ] n e t s a l e s w e n t u p b y 1 % y e a r - o n - y e a r t o e u # # r 2 9 m i l l i o n , a f f e c t e d b y t h e b u s i n e s s a c q u i s i t i o n s , r e a l i z e d d u r i n g t h e p r e v i o u s f i n a n c i a l p e r i o d , t h e e f f e c t o f w h i c h w a s e u # # r 5 . 1 m i l l i o n o n t h e r e v i e w p e r i o d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 113\n",
            "neg_neg 39\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 7\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        17\n",
            "   macro avg       1.00      1.00      1.00        17\n",
            "weighted avg       1.00      1.00      1.00        17\n",
            "\n",
            "[[13  0]\n",
            " [ 0  4]]\n",
            "pos_pos 126\n",
            "neg_neg 43\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 7\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "len dataloader 6\n",
            "  Accuracy: 0.96\n",
            "  avg my accuracy 0.96\n",
            "  Validation Loss: 0.1658\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of     50.    Elapsed: 0:00:16.\n",
            "\n",
            "  Average training loss: 0.0426\n",
            "  Training epoch took: 0:00:19\n",
            "\n",
            "Running Validation...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        24\n",
            "           1       0.80      1.00      0.89         8\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.90      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[22  2]\n",
            " [ 0  8]]\n",
            "sentence [ C L S ] t h e c o m p a n y s t i l l e x p e c t s i t s t u r n o v e r i n 2 0 1 0 t o s l i g h t l y i n c r e a s e f r o m t h e l e v e l o f 2 0 0 9 , a d d i n g t h a t ` ` m a r k e t p r e d i c t # # a b i l i t y i s s t i l l t o o p o o r f o r t r u s t # # w o r t h y f o r e c a s t # # s o n t h e m a r k e t d e v e l o p m e n t o f t h e c o n t r a c t m a n u f a c t u r i n g b u s i n e s s d u r i n g t h e c u r r e n t y e a r ' ' . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] l o s s a f t e r t a x e s a m o u n t e d t o e u # # r 1 . 2 m n c o m p a r e d t o a l o s s o f 2 . 6 m n . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 22\n",
            "neg_neg 8\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 2\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        25\n",
            "           1       0.78      1.00      0.88         7\n",
            "\n",
            "    accuracy                           0.94        32\n",
            "   macro avg       0.89      0.96      0.92        32\n",
            "weighted avg       0.95      0.94      0.94        32\n",
            "\n",
            "[[23  2]\n",
            " [ 0  7]]\n",
            "sentence [ C L S ] t h e s t o c k p r i c e r o s e 7 0 . 0 o r e # # s o r 0 . 9 % t o c l o s e a t s e # # k # # 7 # # 7 . 6 5 , e n d i n g a t w o - d a y s t r e a k o f l o s s e s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] k e y s h a r e h o l d e r s o f f i n n i s h i t s e r v i c e s p r o v i d e r t i e # # t o # # e n a # # t o r o # # y # # j o n f r i d a y r e j e c t e d a h o s t i l e e u # # r # # 1 . 0 8 b i l l i o n $ 1 . 6 7 b i l l i o n o f f e r f r o m b u y # # o u t s h o p n o r d i c c a p i t a l , g i v i n g n e w l i f e t o a p o s s i b l e c o u n t e r o f f e r f r o m b l a c k s # # t o n e g r o u p l p a n d n o r w e g i a n t e l e c o m t e l # # e n o # # r a s a . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 45\n",
            "neg_neg 15\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 4\n",
            "neg_pos 0\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94        26\n",
            "           1       0.71      0.83      0.77         6\n",
            "\n",
            "    accuracy                           0.91        32\n",
            "   macro avg       0.84      0.88      0.86        32\n",
            "weighted avg       0.91      0.91      0.91        32\n",
            "\n",
            "[[24  2]\n",
            " [ 1  5]]\n",
            "sentence [ C L S ] n o k i a w a s u p 0 . 1 2 p c # # t t o 1 6 . 7 0 e u # # r a f t e r k i c k i n g o f f t h e m o r n i n g i n n e g a t i v e t e r r i t o r y . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] c o s t c u t t i n g m e a s u r e s , w h i c h h a v e p r o d u c e d a r o u n d e u # # r # # 7 0 # # m o f s a v i n g s o v e r t h e p a s t n i n e m o n t h s , h a v e d a m p # # e n e d t h e a i r l i n e ' s l o s s , f i n n # # a i r s a i d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "sentence [ C L S ] r a w m a t e r i a l s p r i c e s h a v e s u r g e d i n t h e p a s t y e a r , f u e l e d i n p a r t b e c a u s e o f t h e r a p i d i n d u s t r i a l # # i z a t i o n o f c h i n a , i n d i a a n d o t h e r d e v e l o p i n g n a t i o n s . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 1 0\n",
            "pos_pos 69\n",
            "neg_neg 20\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        22\n",
            "           1       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        32\n",
            "   macro avg       1.00      1.00      1.00        32\n",
            "weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "[[22  0]\n",
            " [ 0 10]]\n",
            "pos_pos 91\n",
            "neg_neg 30\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 6\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        23\n",
            "           1       0.90      1.00      0.95         9\n",
            "\n",
            "    accuracy                           0.97        32\n",
            "   macro avg       0.95      0.98      0.96        32\n",
            "weighted avg       0.97      0.97      0.97        32\n",
            "\n",
            "[[22  1]\n",
            " [ 0  9]]\n",
            "sentence [ C L S ] n e t s a l e s w e n t u p b y 1 % y e a r - o n - y e a r t o e u # # r 2 9 m i l l i o n , a f f e c t e d b y t h e b u s i n e s s a c q u i s i t i o n s , r e a l i z e d d u r i n g t h e p r e v i o u s f i n a n c i a l p e r i o d , t h e e f f e c t o f w h i c h w a s e u # # r 5 . 1 m i l l i o n o n t h e r e v i e w p e r i o d . [ S E P ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] [ P A D ] \n",
            "\n",
            "true label, pred label 0 1\n",
            "pos_pos 113\n",
            "neg_neg 39\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 7\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        13\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00        17\n",
            "   macro avg       1.00      1.00      1.00        17\n",
            "weighted avg       1.00      1.00      1.00        17\n",
            "\n",
            "[[13  0]\n",
            " [ 0  4]]\n",
            "pos_pos 126\n",
            "neg_neg 43\n",
            "neu_neu 0 \n",
            "\n",
            "pos_neg 7\n",
            "neg_pos 1\n",
            "pos_neu 0\n",
            "neu_pos 0\n",
            "neg_neu 0\n",
            "neu_neg 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "len dataloader 6\n",
            "  Accuracy: 0.96\n",
            "  avg my accuracy 0.96\n",
            "  Validation Loss: 0.1637\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:25 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "0e7d0a2c-863f-46e1-bd07-63c154377f1a"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 3)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train Loss</th>\n",
              "      <th>dev Loss</th>\n",
              "      <th>dev Accur.</th>\n",
              "      <th>dev my Accur.</th>\n",
              "      <th>dev precision</th>\n",
              "      <th>dev recall</th>\n",
              "      <th>dev f1_score</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>tn</th>\n",
              "      <th>train Time</th>\n",
              "      <th>dev Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.469</td>\n",
              "      <td>0.182</td>\n",
              "      <td>0.943</td>\n",
              "      <td>0.943</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.932</td>\n",
              "      <td>0.961</td>\n",
              "      <td>20.500</td>\n",
              "      <td>0.167</td>\n",
              "      <td>1.667</td>\n",
              "      <td>7.167</td>\n",
              "      <td>0:00:20</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.133</td>\n",
              "      <td>0.141</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.979</td>\n",
              "      <td>0.960</td>\n",
              "      <td>0.969</td>\n",
              "      <td>21.167</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.000</td>\n",
              "      <td>6.833</td>\n",
              "      <td>0:00:19</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.072</td>\n",
              "      <td>0.166</td>\n",
              "      <td>0.958</td>\n",
              "      <td>0.958</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.972</td>\n",
              "      <td>21.000</td>\n",
              "      <td>0.167</td>\n",
              "      <td>1.167</td>\n",
              "      <td>7.167</td>\n",
              "      <td>0:00:19</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.043</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.958</td>\n",
              "      <td>0.958</td>\n",
              "      <td>0.993</td>\n",
              "      <td>0.953</td>\n",
              "      <td>0.972</td>\n",
              "      <td>21.000</td>\n",
              "      <td>0.167</td>\n",
              "      <td>1.167</td>\n",
              "      <td>7.167</td>\n",
              "      <td>0:00:19</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       train Loss  dev Loss  dev Accur.  ...     tn  train Time  dev Time\n",
              "epoch                                    ...                             \n",
              "1           0.469     0.182       0.943  ...  7.167     0:00:20   0:00:02\n",
              "2           0.133     0.141       0.953  ...  6.833     0:00:19   0:00:02\n",
              "3           0.072     0.166       0.958  ...  7.167     0:00:19   0:00:02\n",
              "4           0.043     0.164       0.958  ...  7.167     0:00:19   0:00:02\n",
              "\n",
              "[4 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLFaS4gwM2Z",
        "outputId": "c2cdb88b-331e-437b-88d7-d2f63d923a9a"
      },
      "source": [
        "print(df_stats.to_latex(index=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{rrrrrrrrrrrll}\n",
            "\\toprule\n",
            " train Loss &  dev Loss &  dev Accur. &  dev my Accur. &  dev precision &  dev recall &  dev f1\\_score &      tp &     fp &     fn &     tn & train Time & dev Time \\\\\n",
            "      0.469 &     0.182 &       0.943 &          0.943 &          0.993 &       0.932 &         0.961 &  20.500 &  0.167 &  1.667 &  7.167 &    0:00:20 &  0:00:02 \\\\\n",
            "\\midrule\n",
            "      0.133 &     0.141 &       0.953 &          0.953 &          0.979 &       0.960 &         0.969 &  21.167 &  0.500 &  1.000 &  6.833 &    0:00:19 &  0:00:02 \\\\\n",
            "      0.072 &     0.166 &       0.958 &          0.958 &          0.993 &       0.953 &         0.972 &  21.000 &  0.167 &  1.167 &  7.167 &    0:00:19 &  0:00:02 \\\\\n",
            "      0.043 &     0.164 &       0.958 &          0.958 &          0.993 &       0.953 &         0.972 &  21.000 &  0.167 &  1.167 &  7.167 &    0:00:19 &  0:00:02 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "1d1c397f-109e-48e3-8289-1f7fefc62a56"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['train loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['dev loss'], 'g-o', label=\"dev\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & dev loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1hUV94H8O8Mwwy9g4USFQWUZi+RqGABewNr7DV2d5Ooq6m7xjdqYtfEktg1NDtWLNGN0VgWLKARK9ah9zLMvH+4zDoBdcCBO8D38zzv8+6ce++535lwHn9z59xzRSqVSgUiIiIiIhKMWOgAREREREQ1HYtyIiIiIiKBsSgnIiIiIhIYi3IiIiIiIoGxKCciIiIiEhiLciIiIiIigbEoJ6JqKzExEe7u7li1alW5+5g7dy7c3d11mKr6et3n7e7ujrlz52rVx6pVq+Du7o7ExESd54uMjIS7uzsuXLig876JiN6VROgARFRzlKW4jY6OhpOTUwWmqXpycnLwww8/ICoqCi9evICNjQ1atGiBKVOmwNXVVas+ZsyYgaNHj2Lv3r1o3LhxqfuoVCp07twZGRkZOHfuHIyMjHT5NirUhQsXcPHiRYwaNQoWFhZCxykhMTERnTt3xvDhw/H5558LHYeI9AiLciKqNIsXL9Z4ffnyZfzyyy8YPHgwWrRoobHNxsbmnc/n6OiI2NhYGBgYlLuPf/7zn/jqq6/eOYsuLFiwAIcOHUKvXr3QunVryOVynDx5EjExMVoX5cHBwTh69CgiIiKwYMGCUvf5/fff8fjxYwwePFgnBXlsbCzE4sr5YfbixYtYvXo1+vfvX6Io79u3L3r27AlDQ8NKyUJEVBYsyomo0vTt21fjdVFREX755Rc0bdq0xLa/ysrKgpmZWZnOJxKJIJPJypzzVfpSwOXm5uLIkSPw8/PDd999p26fNm0aCgoKtO7Hz88PderUwYEDB/Dpp59CKpWW2CcyMhLAywJeF971v4GuGBgYvNMXNCKiisQ55USkdwICAjBixAjcvHkT48aNQ4sWLdCnTx8AL4vzZcuWISQkBG3atIGXlxe6du2KpUuXIjc3V6Of0uY4v9p26tQpDBw4EN7e3vDz88O3334LhUKh0Udpc8qL2zIzM/HFF1+gXbt28Pb2xpAhQxATE1Pi/aSmpmLevHlo06YNmjVrhpEjR+LmzZsYMWIEAgICtPpMRCIRRCJRqV8SSiusX0csFqN///5IS0vDyZMnS2zPysrCsWPH4ObmBh8fnzJ93q9T2pxypVKJH3/8EQEBAfD29kavXr2wf//+Uo9PSEjAl19+iZ49e6JZs2bw9fXFgAEDEBYWprHf3LlzsXr1agBA586d4e7urvHf/3VzylNSUvDVV1+hY8eO8PLyQseOHfHVV18hNTVVY7/i48+fP49NmzahS5cu8PLyQmBgIPbs2aPVZ1EW8fHxmDp1Ktq0aQNvb2/06NEDGzZsQFFRkcZ+T58+xbx58+Dv7w8vLy+0a9cOQ4YM0cikVCqxefNm9O7dG82aNUPz5s0RGBiIf/zjHygsLNR5diIqO14pJyK99OTJE4waNQpBQUHo1q0bcnJyAADPnz9HeHg4unXrhl69ekEikeDixYvYuHEj4uLisGnTJq36P3PmDHbu3IkhQ4Zg4MCBiI6Oxk8//QRLS0tMnjxZqz7GjRsHGxsbTJ06FWlpafj5558xceJEREdHq6/qFxQUYMyYMYiLi8OAAQPg7e2NW7duYcyYMbC0tNT68zAyMkK/fv0QERGBgwcPolevXlof+1cDBgzAunXrEBkZiaCgII1thw4dQl5eHgYOHAhAd5/3Xy1atAhbt25Fq1atMHr0aCQnJ+Prr7+Gs7NziX0vXryIS5cuoVOnTnByclL/arBgwQKkpKRg0qRJAIDBgwcjKysLx48fx7x582BtbQ3gzfcyZGZmYujQoXjw4AEGDhyIJk2aIC4uDrt27cLvv/+OsLCwEr/QLFu2DHl5eRg8eDCkUil27dqFuXPnwsXFpcQ0rPK6du0aRowYAYlEguHDh8POzg6nTp3C0qVLER8fr/61RKFQYMyYMXj+/DmGDRuGevXqISsrC7du3cKlS5fQv39/AMC6deuwcuVK+Pv7Y8iQITAwMEBiYiJOnjyJgoICvflFiKhGUxERCSQiIkLl5uamioiI0Gj39/dXubm5qUJDQ0sck5+fryooKCjRvmzZMpWbm5sqJiZG3fbo0SOVm5ubauXKlSXafH19VY8ePVK3K5VKVc+ePVXt27fX6HfOnDkqNze3Utu++OILjfaoqCiVm5ubateuXeq27du3q9zc3FRr167V2Le43d/fv8R7KU1mZqZqwoQJKi8vL1WTJk1Uhw4d0uq41xk5cqSqcePGqufPn2u0Dxo0SOXp6alKTk5WqVTv/nmrVCqVm5ubas6cOerXCQkJKnd3d9XIkSNVCoVC3X79+nWVu7u7ys3NTeO/TXZ2donzFxUVqT788ENV8+bNNfKtXLmyxPHFiv/efv/9d3Xb999/r3Jzc1Nt375dY9/i/z7Lli0rcXzfvn1V+fn56vZnz56pPD09VbNnzy5xzr8q/oy++uqrN+43ePBgVePGjVVxcXHqNqVSqZoxY4bKzc1N9dtvv6lUKpUqLi5O5ebmplq/fv0b++vXr5+qe/fub81HRMLh9BUi0ktWVlYYMGBAiXapVKq+qqdQKJCeno6UlBS8//77AFDq9JHSdO7cWWN1F5FIhDZt2kAulyM7O1urPkaPHq3xum3btgCABw8eqNtOnToFAwMDjBw5UmPfkJAQmJuba3UepVKJmTNnIj4+HocPH0aHDh3w8ccf48CBAxr7ffbZZ/D09NRqjnlwcDCKioqwd+9edVtCQgL+85//ICAgQH2jra4+71dFR0dDpVJhzJgxGnO8PT090b59+xL7m5iYqP93fn4+UlNTkZaWhvbt2yMrKwt3794tc4Zix48fh42NDQYPHqzRPnjwYNjY2ODEiRMljhk2bJjGlKFatWqhfv36uH//frlzvCo5ORlXr15FQEAAPDw81O0ikQgfffSROjcA9d/QhQsXkJyc/No+zczM8Pz5c1y6dEknGYlI9zh9hYj0krOz82tvytuxYwd2796NO3fuQKlUamxLT0/Xuv+/srKyAgCkpaXB1NS0zH0UT5dIS0tTtyUmJsLBwaFEf1KpFE5OTsjIyHjreaKjo3Hu3DksWbIETk5OWLFiBaZNm4ZPP/0UCoVCPUXh1q1b8Pb21mqOebdu3WBhYYHIyEhMnDgRABAREQEA6qkrxXTxeb/q0aNHAIAGDRqU2Obq6opz585ptGVnZ2P16tU4fPgwnj59WuIYbT7D10lMTISXlxckEs1/DiUSCerVq4ebN2+WOOZ1fzuPHz8ud46/ZgKAhg0bltjWoEEDiMVi9Wfo6OiIyZMnY/369fDz80Pjxo3Rtm1bBAUFwcfHR33c3/72N0ydOhXDhw+Hg4MDWrdujU6dOiEwMLBM9yQQUcVhUU5EesnY2LjU9p9//hn/93//Bz8/P4wcORIODg4wNDTE8+fPMXfuXKhUKq36f9MqHO/ah7bHa6v4xsRWrVoBeFnQr169Gh999BHmzZsHhUIBDw8PxMTEYOHChVr1KZPJ0KtXL+zcuRNXrlyBr68v9u/fj9q1a+ODDz5Q76erz/td/P3vf8fp06cxaNAgtGrVClZWVjAwMMCZM2ewefPmEl8UKlplLe+ordmzZyM4OBinT5/GpUuXEB4ejk2bNmH8+PH45JNPAADNmjXD8ePHce7cOVy4cAEXLlzAwYMHsW7dOuzcuVP9hZSIhMOinIiqlH379sHR0REbNmzQKI5+/fVXAVO9nqOjI86fP4/s7GyNq+WFhYVITEzU6gE3xe/z8ePHqFOnDoCXhfnatWsxefJkfPbZZ3B0dISbmxv69eundbbg4GDs3LkTkZGRSE9Ph1wux+TJkzU+14r4vIuvNN+9excuLi4a2xISEjReZ2Rk4PTp0+jbty++/vprjW2//fZbib5FIlGZs9y7dw8KhULjarlCocD9+/dLvSpe0YqnVd25c6fEtrt370KpVJbI5ezsjBEjRmDEiBHIz8/HuHHjsHHjRowdOxa2trYAAFNTUwQGBiIwMBDAy19Avv76a4SHh2P8+PEV/K6I6G306+s+EdFbiMViiEQijSu0CoUCGzZsEDDV6wUEBKCoqAhbt27VaA8NDUVmZqZWfXTs2BHAy1U/Xp0vLpPJ8P3338PCwgKJiYkIDAwsMQ3jTTw9PdG4cWNERUVhx44dEIlEJdYmr4jPOyAgACKRCD///LPG8n43btwoUWgXfxH46xX5Fy9elFgSEfjf/HNtp9V06dIFKSkpJfoKDQ1FSkoKunTpolU/umRra4tmzZrh1KlTuH37trpdpVJh/fr1AICuXbsCeLl6zF+XNJTJZOqpQcWfQ0pKSonzeHp6auxDRMLilXIiqlKCgoLw3XffYcKECejatSuysrJw8ODBMhWjlSkkJAS7d+/G8uXL8fDhQ/WSiEeOHMF7771XYl300rRv3x7BwcEIDw9Hz5490bdvX9SuXRuPHj3Cvn37ALwssNasWQNXV1d0795d63zBwcH45z//ibNnz6J169YlrsBWxOft6uqK4cOHY/v27Rg1ahS6deuG5ORk7NixAx4eHhrzuM3MzNC+fXvs378fRkZG8Pb2xuPHj/HLL7/AyclJY/4+APj6+gIAli5dit69e0Mmk6FRo0Zwc3MrNcv48eNx5MgRfP3117h58yYaN26MuLg4hIeHo379+hV2Bfn69etYu3ZtiXaJRIKJEydi/vz5GDFiBIYPH45hw4bB3t4ep06dwrlz59CrVy+0a9cOwMupTZ999hm6deuG+vXrw9TUFNevX0d4eDh8fX3VxXmPHj3QtGlT+Pj4wMHBAXK5HKGhoTA0NETPnj0r5D0SUdno579iRESvMW7cOKhUKoSHh2PhwoWwt7dH9+7dMXDgQPTo0UPoeCVIpVJs2bIFixcvRnR0NA4fPgwfHx9s3rwZ8+fPR15enlb9LFy4EK1bt8bu3buxadMmFBYWwtHREUFBQRg7diykUikGDx6MTz75BObm5vDz89Oq3969e2Px4sXIz88vcYMnUHGf9/z582FnZ4fQ0FAsXrwY9erVw+eff44HDx6UuLlyyZIl+O6773Dy5Ens2bMH9erVw+zZsyGRSDBv3jyNfVu0aIGPP/4Yu3fvxmeffQaFQoFp06a9tig3NzfHrl27sHLlSpw8eRKRkZGwtbXFkCFDMH369DI/RVZbMTExpa5cI5VKMXHiRHh7e2P37t1YuXIldu3ahZycHDg7O+Pjjz/G2LFj1fu7u7uja9euuHjxIg4cOAClUok6depg0qRJGvuNHTsWZ86cwbZt25CZmQlbW1v4+vpi0qRJGiu8EJFwRKrKuEuHiIg0FBUVoW3btvDx8Sn3A3iIiKj64JxyIqIKVtrV8N27dyMjI6PUdbmJiKjm4fQVIqIKtmDBAhQUFKBZs2aQSqW4evUqDh48iPfeew+DBg0SOh4REekBTl8hIqpge/fuxY4dO3D//n3k5OTA1tYWHTt2xMyZM2FnZyd0PCIi0gMsyomIiIiIBMY55UREREREAmNRTkREREQkMN7o+V+pqdlQKit3Jo+trRmSk7Mq9ZxEVRHHCpF2OFaItCPUWBGLRbC2Ni11G4vy/1IqVZVelBefl4jejmOFSDscK0Ta0bexwukrREREREQCY1FORERERCQwFuVERERERAJjUU5EREREJDAW5UREREREAuPqK0RERERvkJubjaysdBQVFQodhXTkxQsxlEqlzvozMDCEmZkljI1LX+5QGyzKiYiIiF6jsLAAmZmpsLKyg6GhDCKRSOhIpAMSiRgKhW6KcpVKhcLCfKSlJUEiMYShobRc/XD6ChEREdFrZGamwczMElKpEQtyKpVIJIJUagRTU0tkZaWVux8W5URERESvoVAUQCYzFjoGVQFGRsYoLCwo9/GcviKA8zeeIfJMAlIy8mFjIcOAjq5o51lb6FhERET0F0plEcRiA6FjUBUgFhtAqSwq9/EsyivZ+RvPsOVwPAr+O48pOSMfWw7HAwALcyIiIj3EaSukjXf9O+H0lUoWeSZBXZAXK1AoEXkmQaBERERERCQ0FuWVLDkjv0ztRERERFXNtGkTMW3axEo/tirj9JVKZmshK7UAt7GQCZCGiIiIahI/v5Za7RcWth916tSt4DT0KhbllWxAR1eNOeXFalkbQ6VScd4aERERVZjPPvta43Vo6C48f/4U06f/TaPdysr6nc6zbNkaQY6tyliUV7LimzlfXX3F0c4UsXdTcOyPRwhs7SJwQiIiIqquAgN7aLw+fToa6elpJdr/Ki8vD0ZGRlqfx9DQsFz53vXYqoxFuQDaedZGO8/asLc3h1yeCaVKhR/2XkfoyTuwtTBCSw8HoSMSERFRDTVt2kRkZWXh00//gVWrluHWrXgMHz4S48ZNwtmzp7F//x7cvn0LGRnpsLd3QI8evTFixBgYGBho9AEAq1evBwBcuXIJM2ZMxsKFi3Hv3l3s3RuBjIx0eHv74pNP/gEnJ2edHAsAERGh2L17B5KTk+Dq6opp02Zjw4Z1Gn3qIxblekAsEmF8ryZIzbqKDQdvwtpcBldHS6FjERERUQUofl5JckY+bPX0eSVpaan49NPZ6NYtCEFBPVGr1st8UVEHYWxsgsGDh8PExBiXL1/Cxo0/IDs7G1Onznxrv1u2bIJYbIBhw0YiMzMDu3Ztw1dfLcCGDVt0cuyePeFYtmwxmjZtjsGDh+Lp06eYN+9jmJubw95evy96sijXE1JDA0wf6INvtl7GyohYzB/RAg7WJkLHIiIiIh2qKs8rSUqSY+7cz9CrV1+N9i+//Bdksv9NY+nXLxhLlnyDPXvCMGHCR5BKpW/sV6FQ4KeftkAieVmCWlhYYsWKpbh79w4aNGj4TscWFhZi48Z18PT0xvLla9X7NWzYCAsXfsminLRnYSLFrEG+WLj1EpaFvSzMzYxr5rwqIiIiffXva09xLvZpuY5NeJIORZFKo61AocTPUXH49T9PytSXn08dtPeuU64cb2NkZISgoJ4l2l8tyHNyslFQUAhf32bYty8SDx7cR6NGbm/st2fPPupiGQB8fZsCAJ48efzWovxtx8bH30R6ejqmTOmvsV/XrkFYufL7N/atD1iU65naNiaYPtAHS3dfxeqIWPx9SFMYSvh4XyIiourgrwX529qFYm/voFHYFrt7NwEbNqzDlSt/IDs7W2NbdnbWW/stngZTzNzcAgCQmZn5zsc+e/byi9Jf55hLJBLUqVMxX150iUW5HnJztsK4nk3w4/4b2HQoDhP7eELMpRKJiIj0Qnvv8l+h/mTtv0t9XomthQxzhjd/12g68+oV8WKZmZmYPn0iTEzMMG7cZDg6OkEqleL27XisW7cKSqWylJ40icWlX2hUqd7+peRdjq0K+ERPPdWmSS0M7NgAF+NeYM+vd4WOQ0RERDowoKMrpBLN8ksqEWNAR1eBEmnv6tXLSE9Px/z5X2DQoKFo3/4DtGrVRn3FWmi1a7/8opSY+EijXaFQ4OnT8k03qkwsyvVYj7bvoYNvXRw6/wC/xpRtnhkRERHpn3aetTGquwds//skb1sLGUZ199CrmzxfRyx+WTa+emW6sLAQe/aECRVJg4dHE1haWmL//j1QKBTq9uPHjyAzM0PAZNrh9BU9JhKJ8GE3N6Rk5GHrkVuwsZDBq76t0LGIiIjoHRQ/r6Sq8fb2gbm5BRYu/BLBwYMhEolw9GgU9GX2iKGhIcaOnYhly5Zg1qwp8PfvjKdPn+Lw4QNwdHTS+6em80q5npMYiPFRPy/UtTPF2j3X8ejF22+iICIiItI1S0srLF68DLa2dtiwYR127dqOli3bYMqUGUJHUxs4cDBmzfoYz549xZo1KxATcxX/93/fw8zMHFKpTOh4byRSVZfZ8e8oOTkLSmXlfhTFT/TURkpGHhZuuwwAWDCyJazN9fsPi0iXyjJWiGoyjhXde/bsAWrXfk/oGPQOlEolevXqio4d/TFnzgIAgEQihkLx9htTy+ptfy9isQi2tmalb9N5GqoQNhZGmBnsg5x8BVaExSA3X/H2g4iIiIhqkPz8kivbHDlyCBkZ6WjWrIUAibTHOeVViEstc0zp54UVYbH4Yd8NzAj2hoGY36uIiIiIACA29j9Yt24VOnUKgIWFJW7fjsehQ/vRoIEr/P27CB3vjViUVzHeDWzxYaAbth65hR3H/8SIbm56f+MCERERUWWoW9cRdnb2CA//BRkZ6bCwsERQUE9MnjwNhob6/ZR0FuVVUKemjkhKy0PU7w9gb2mE7m05142IiIjI0dEJixcvEzpGubAor6IGdGyApPRchJ1OgK2lEVo3riV0JCIiIiIqJxblVZRYJMK4no2RkpmPjQfjYG0uQyMnK6FjEREREVE58C7BKsxQYoDpA7xhayHDqohreJ6SI3QkIiIiIioHFuVVnLmJFLMG+QIAloXFIDOnQOBERERERFRWLMqrgVrWJpgx0AcpGflYFXENhYoioSMRERERURmwKK8mGjpZYmLvJrjzOB0bD8ZByQe1EhEREVUZLMqrkZYeDhjk3xB/xL9AxJkEoeMQERERkZZYlFczga2d4d/MEYd/f4jTVx8LHYeIiIiquaioA/Dza4mnT5+o24KDe2Phwi/Ldey7unLlEvz8WuLKlUs667MysCivZkQiEYZ1bQQfV1tsP3YbsQnJQkciIiIiPfLpp7PRpYsfcnNzX7vP3/42DYGBHZGfn1+JycrmxImjCA3dKXQMnWFRXg0ZiMWY3NcTTg6mWLfvOh4+zxQ6EhEREemJrl0DkZeXh3PnzpS6PTU1BZcv/4EOHfwhk8nKdY6dOyMwZ86Cd4n5VtHRxxAauqtEe9OmzREd/W80bdq8Qs+vayzKqykjqQQzg31hIpNgeVgMUjLyhI5EREREeuCDDzrB2NgEJ04cLXX7yZMnUFRUhG7dgsp9DqlUColEmGdUisViyGQyiMVVq8ytWmmpTKzNZZgd4ou8giIsD4tBbr5C6EhEREQkMCMjI3zwQUdcvPg7MjIySmw/ceIobG1t4ez8HpYu/T8MHToAAQHt0aNHZyxYMEer+d+lzSm/ezcBM2ZMRkBAe/Tv3wObN2+EUqkscezZs6fxyScz0bdvEPz922HQoL7YvHkjior+t+TztGkTcfbsGTx79hR+fi3h59cSwcG9Abx+Tnl09DGMGTMMAQHvo3v3zli06GukpaVp7DNt2kSMHj0Md+/ewbRpE9G5c3v069cdO3Zseet7flfCfIWhSuPkYIap/b2xPCwGa/dex8xgH0gM+F2MiIhIKBefXcH+hCNIzU+DtcwKfVyD0Lp25U616No1CMeOHcbp09Ho06e/uv3Zs6e4fj0WwcFDEBd3A9evx6JLl0DY2zvg6dMn2Ls3AtOnT8L27WEwMjLS+nzJyUmYMWMylEolPvxwFIyMjLF//55Sp8dERR2EsbEJBg8eDhMTY1y+fAkbN/6A7OxsTJ06EwAwatRY5Obm4vnzp5g+/W8AAGNjk9eePyrqAL755it4enrjo49mICnpOcLCfkFc3A1s2LBVI0dGRjr+/vcZ8PfvjM6du+HUqRNYt24VGjRoiHbt2mv9nsuKRXkN4FnfBiMC3bH5cDy2H7uFUUEeEIlEQsciIiKqcS4+u4Kd8REoVBYCAFLz07AzPgIAKrUwb9WqDaysrHHixFGNovzEiaNQqVTo2jUQrq4N4e/fReO49u07YPLkMTh9OhpBQT21Pt+OHVuQnp6GjRu3wd3dAwDQvXsvDB3av8S+X375L8hk/yv4+/ULxpIl32DPnjBMmPARpFIpWrVqi8jIMKSnpyEwsMcbz61QKLBu3So0bOiGVat+/O/UGjEaNfLAl1/Ox4EDexAcPES9/4sXz/HFF/9C164vp+/06tUXwcG9cOjQPhbl9O46+NZFUnouDv72APZWxujZrp7QkYiIiKqkC08v4/zTP8p17L30h1CoNKeTFioLsSMuHL89uVimvtrVaYU2dVqUK4dEIkFAQBfs3RuBpKQk2NnZAQBOnDgGJydnNGnipbG/QqFAdnYWnJycYWZmjtu348tUlJ8//294e/uqC3IAsLa2Rteu3bFnT5jGvq8W5Dk52SgoKISvbzPs2xeJBw/uo1EjtzK91/j4m0hNTVEX9MUCArpizZoV+O23f2sU5WZmZujSJVD92tDQEI0be+LJk4pdappFeQ3S/4MGSErLQ8SZu7C1NELbJrWFjkRERFSj/LUgf1t7ReraNQiRkWE4efIYBg0ahvv37+HOndsYM2YCACA/Pw/btm1GVNQByOUvoHrlaeFZWVllOtfz58/g7e1bot3F5b0SbXfvJmDDhnW4cuUPZGdna2zLzi7beYGXU3JKO5dYLIaTkzOeP3+q0e7gUKvEjAJzcwskJNwp87nLgkV5DSISiTCmR2OkZObjp0NxsDE3gpuzldCxiIiIqpQ2dVqU+wr1gn9/g9T8tBLt1jIrzGo++V2jlYm3ty/q1HHE8eNHMGjQMBw/fgQA1NM2li1bgqioAwgJGQovL2+YmZkBEOHLL/+hUaDrUmZmJqZPnwgTEzOMGzcZjo5OkEqluH07HuvWrSr1xlBdE4sNSm2vqPesPm+F9k56x1AixrQB3rCzNMaqiFg8Tc5++0FERESkE31cg2AoNtRoMxQboo9r+ZcffBddunRDXNxNJCY+QnT0Mbi7N1ZfUS6eNz59+mz4+3dBq1Zt4ePTtMxXyQGgVq3aSEx8VKL94cMHGq+vXr2M9PR0zJ//BQYNGor27T9Aq1ZtYG5uUUqv2t0fV7t2nVLPpVKpkJj4CLVq1dHuTVQwFuU1kJmxIWYN8oVYLMLysBhk5BQIHYmIiKhGaF27OYZ5DIS17OUv1dYyKwzzGFjpq68U69atOwBg9eplSEx8pLE2eWlXjCMiftFYmlBb7dq1x7VrMbh1K17dlpqaiuPHD2vsV7y2+KtXpQsLC0vMOwcAY2NjrZDuimYAACAASURBVL4geHg0gbW1DfbuDUdhYaG6/dSpaMjlL/D++xV382ZZcPpKDeVgZYwZwT5YvPMqVoXH4pOhzSA1LP3nGiIiItKd1rWbC1aE/1X9+g3QsKEbzp37FWKxGJ07/+8Gx/ff98PRo1EwNTVDvXr1cePGNVy6dBGWlpZlPs+wYaNw9GgU/va3qQgOHgKZzAj79+9BrVp1kJX1p3o/b28fmJtbYOHCLxEcPBgikQhHj0ahtJkj7u4eOHbsMFat+h4eHk1gbGwCP78OJfaTSCT46KPp+OabrzB9+iR06dINcvkLhIXtRoMGrujdu+QKMELglfIazLWuJSb2boK7TzKw4cBNKCt4rhQRERHpn+Kr482atVCvwgIAM2d+jMDAHjh+/DBWr16OpKQkLF++5o3rgb+OnZ0dVq78EfXru2Lbts0IC9uFoKAeCAkZorGfpaUVFi9eBltbO2zYsA67dm1Hy5ZtMGXKjBJ99u07EIGB3REVdRBffbUAy5cvee35e/TojS+/XIj8/DysWbMChw7tR9euQVix4odS10oXgkhV0bPWq4jk5CwolZX7Udjbm0Muz6zUc5bm2MWH2H3yDgJbO2NwQCOh4xCVoC9jhUjfcazo3rNnD1C7dskVQqhqk0jEUCh0f9Po2/5exGIRbG3NSs+k8zRU5XRt5Qx5Wh6OXnwEO0tjdG7hJHQkIiIiohpF0OkrBQUFWLJkCfz8/ODj44NBgwbh/PnzZe5nwoQJcHd3x8KFCysgZfUnEokwtEsjNG1oh50nbuM/d5KEjkRERERUowhalM+dOxdbtmxBnz59MH/+fIjFYkyYMAFXr17Vuo/Tp0/j0qVLFZiyZhCLRZjUxxMutczxw77ruP8sQ+hIRERERDWGYEV5bGwsDh06hI8//hiffvopBg8ejC1btqBOnTpYunSpVn0UFBRg0aJFGDduXAWnrRlkUgPMCvaBubEUK8JikZyeJ3QkIiIiohpBsKL8yJEjMDQ0REhIiLpNJpMhODgYly9fxosXL97ax9atW5GXl8eiXIcszWSYFeKDAoUSy8NikJNX+Y/9JSIiIqppBCvK4+LiUL9+fZiammq0+/j4QKVSIS4u7o3Hy+VyrF27FrNnz4axsXFFRq1xHO3NMK2/F56l5GDNnmtQFFX8I22JiIiIajLBinK5XA4HB4cS7fb29gDw1ivl33//PerXr4++fftWSL6arnE9G4zu7oG4B6nYeuQWuHImERERUcURbEnEvLw8GBoalmgvXsA9Pz//tcfGxsZi79692LZtG0QikU7yvG7NyIpmb28uyHm10S/AHDmFSuw6dgvvOVpiSFd3oSNRDabPY4VIn3Cs6NaLF2IYGIh0Vm+Q/pBIdHttWqVSQSwWl3sMClaUGxkZobCwsER7cTH+uqcrqVQqLFy4EN26dUPLli11lqcmPzzoTbo0q4v7j9Ox40g8TCRitPOqLXQkqoGqwlgh0gccK7onEomRm5sHqVQ/nvpIulERDw8qKMiHSCR+4xh808ODBJu+Ym9vX+oUFblcDgClTm0BgOPHjyM2NhZDhw5FYmKi+v8AICsrC4mJicjL46ohuiISiTCmhwc8XKzwU1Qc4h+kCh2JiIio0piZWSEtTY6CgnxO5aRSqVQqFBTkIy1NDjMzq3L3I9iVcg8PD2zbtg3Z2dkaN3vGxMSot5fmyZMnUCqVGDVqVIltkZGRiIyMxIYNG9ChQ4eKCV4DSQzEmDrAG99su4zVkdfwjxEtUNfO9O0HEhERVXHGxi//vUtPT0JREVckqy7EYjGUSt1dKTcwkMDc3Fr991IeghXlQUFB+OmnnxAWFobRo0cDeLnueGRkJJo3b45atWoBeFmE5+bmwtXVFQAQEBAAJ6eSj4GfOnUq/P39ERwcDE9Pz0p7HzWFqZEhZof44l/bLmN5WAzmj2wJS1Op0LGIiIgqnLGx6TsVW6R/9HGql2BFua+vL4KCgrB06VLI5XK4uLhgz549ePLkCRYtWqTeb86cObh48SJu3boFAHBxcYGLi0upfTo7O6NLly6Vkr8msrMyxsxgH3y78wpWhsfg02HNITM0EDoWERERUZUn2JxyAFi8eDFGjBiBffv24V//+hcUCgXWr1+PFi1aCBmL3qB+HQtM6uOJ+08zsX7/jUq/OZaIiIioOhKpeNcCAK6+UlYnLj3CzhN/omtLZwzt0kjoOFTNVeWxQlSZOFaItCPUWHnT6iuCTV+hqq1LS2fI0/Jw/NIj2FkZoWtLZ6EjEREREVVZLMqp3AYHNERSei52n/gTdhZGaOZmL3QkIiIioipJ0DnlVLWJxSJM7OOJenXM8eP+G7j3NEPoSERERERVEotyeicyQwPMCPaFhakUK8JiIE/LFToSERERUZXDopzemaWpFLNCfKEoUmF5WAyy8wqFjkRERERUpbAoJ52oa2eK6QO98SI1F2sir0FRpLunZBERERFVdyzKSWfcXawxtmdjxD9Mw89R8eBqm0RERETa4eorpFPtPGsjKS0Xe87eg72VEfp90EDoSERERER6j0U56Vyv9+tBnpaH/f++D3srY7T3riN0JCIiIiK9xqKcdE4kEmFkkDtSMvOw+XA8rM1laFLPRuhYRERERHqLc8qpQkgMxJjSzxu1bUywZs91PJZnCR2JiIiISG+xKKcKY2IkwawQX0glYiwPi0F6Vr7QkYiIiIj0EotyqlC2lkaYFeKLrFwFlofHIq9AIXQkIiIiIr3Dopwq3Hu1zTGprycePs/Ej/tuQKnkUolEREREr2JRTpWiaUM7DO/qhpiEZOw8cZtrmBMRERG9gquvUKUJaO6EpLQ8HLn4EA5WxujW2kXoSERERER6gUU5Vapgf1fI03Pxy8k7sLU0Qgt3B6EjEREREQmO01eoUolFIkzo1QQN6lpg/YGbSHiSLnQkIiIiIsGxKKdKJzU0wPRgH1iZSbEyPBYv0nKFjkREREQkKBblJAgLEylmD2oKpVKF5aExyMotFDoSERERkWBYlJNgatuYYPpAHySl52J15DUUKpRCRyIiIiISBItyEpSbsxXG9myM24/S8HNUHJdKJCIiohqJq6+Q4No2qY3k9DxEnLkLOysjDOjgKnQkIiIiokrFopz0Qo+270GelouDvz2AnaUxOvjWFToSERERUaVhUU56QSQS4cNu7kjJyMfWI7dgYyGDV31boWMRERERVQrOKSe9ITEQ46N+XqhrZ4q1e64j8UWW0JGIiIiIKgWLctIrxjIJZoX4wEhqgGVhMUjNzBc6EhEREVGFY1FOesfGwgizQnyRk6/AirAY5OYrhI5EREREVKFYlJNecqlljo/6eiFRno0f999AkZJrmBMREVH1xaKc9JaPqy0+DHRDbEIydhz/k2uYExERUbXF1VdIr3Vq6gh5Wi4O//4QDlbGCGrjInQkIiIiIp1jUU56b2BHVySl5SH01B3YWhqhlYeD0JGIiIiIdIpFOek9sUiE8b0aIzUzHxsO3IS1mQwNnSyFjkVERESkM5xTTlWCocQA0wd6w9ZChpURsXiemiN0JCIiIiKdYVFOVYa5iRSzBvkCAJaFxiAzp0DgRERERES6waKcqpRa1iaYMdAHKRn5WBV5DYWKIqEjEREREb0zFuVU5TR0ssSE3k1wJzEdmw7FQcmlEomIiKiKY1FOVVIrDweE+LviYtwLRJ65K3QcIiIionfC1Veoygpq7QJ5Wh6ifn8AOysjdGrqKHQkIiIionJhUU5VlkgkwvCujZCcnoftR2/D1sII3g1shY5FREREVGacvkJVmoFYjMl9PeFkb4q1e6/j4fNMoSMRERERlRmLcqryjGUSzAzxhYlMghXhsUjJyBM6EhEREVGZsCinasHaXIZZIb7IzVdgeVgscvMVQkciIiIi0hqLcqo2nB3MMKW/F54kZWPd3utQFCmFjkRERESkFRblVK141bfFyCB3XL+Xgu3HbkHFNcyJiIioCuDqK1TtdPCti6T0XBz87QHsrYzRs109oSMRERERvRGLcqqW+n/QAElpeYg4cxd2lsZo06SW0JGIiIiIXotFOVVLIpEIY3o0RkpGHjYduglrcxncnK2EjkVERERUKs4pp2rLUCLGtIE+sLM0xqqIWDxLyRE6EhEREVGpWJRTtWZmbIhZg3whFouwPDQGGTkFQkciIiIiKoFFOVV7DlbGmDHQB6lZ+VgVEYuCwiKhIxERERFpYFFONYKroyUm9GqCu48zsPHgTSi5VCIRERHpERblVGO09HDAoICGuHRLjvBTCULHISIiIlLj6itUo3Rr5YyktDwcufgQdlZGCGjuJHQkIiIiIhblVLOIRCIM7dIIyRl52HH8NmwtjODb0E7oWERERFTDCTp9paCgAEuWLIGfnx98fHwwaNAgnD9//q3H7d+/HyNHjkT79u3h5eWFgIAAzJs3D48fP66E1FTVicUiTOrjCZda5vhh3w08eJYpdCQiIiKq4QQtyufOnYstW7agT58+mD9/PsRiMSZMmICrV6++8bj4+HjUqlULY8eOxZdffol+/frh7NmzCA4Ohlwur6T0VJXJpAaYGewDM2MJlofHIDk9T+hIREREVIOJVCphlqGIjY1FSEgI5s2bh9GjRwMA8vPz0atXLzg4OGDHjh1l6u/GjRsYMGAAPv30U4wbN67MeZKTs6BUVu5HYW9vDrmcV2mF9FiehW+2X4aNhRHmDW8BEyPO6NJHHCtE2uFYIdKOUGNFLBbB1tas9G2VnEXtyJEjMDQ0REhIiLpNJpMhODgYly9fxosXL8rUX926dQEAGRkZOs1J1ZujvRmm9vfGs+QcrN17DYoipdCRiIiIqAYSrCiPi4tD/fr1YWpqqtHu4+MDlUqFuLi4t/aRlpaG5ORkXLt2DfPmzQMAtGvXrkLyUvXVpJ4NRgV54Ob9VGw9egsC/XhERERENZhgv9XL5XLUqlWrRLu9vT0AaHWlPDAwEGlpaQAAKysrfP7552jbtq1ug1KN4OdTB0npudj/7/uwtzJG7/frCR2JiIiIahDBivK8vDwYGhqWaJfJZABezi9/m9WrVyMnJwf37t3D/v37kZ2dXe48r5vfU9Hs7c0FOS+VNL6/DzLzFNjz6100cLJCpxbOQkeiV3CsEGmHY4VIO/o2VgQryo2MjFBYWFiivbgYLy7O36RVq1YAgI4dO6Jz587o3bs3TExM8OGHH5Y5D2/0JAAYGtAQT+VZWPHLVUiggruLtdCRCBwrRNriWCHSDm/0fIW9vX2pU1SKlzR0cHAoU3/Ozs7w9PTEgQMHdJKPaiaJgRhTB3jD3soYqyKu4UlS+X99ISIiItKWYEW5h4cH7t27V2LKSUxMjHp7WeXl5SEzk1cI6N2YGhlidogvJAYiLA+LQXp2gdCRiIiIqJoTrCgPCgpCYWEhwsLC1G0FBQWIjIxE8+bN1TeBPnnyBAkJCRrHpqSklOjv+vXriI+Ph6enZ8UGpxrBzsoYM0N8kZFdgJXhscgvLBI6EhEREVVjgs0p9/X1RVBQEJYuXQq5XA4XFxfs2bMHT548waJFi9T7zZkzBxcvXsStW7fUbf7+/ujevTvc3NxgYmKCO3fuICIiAqamppgyZYoQb4eqofp1LDCpjydWR17DhgM3MaWfF8RikdCxiIiIqBoS9PGFixcvxvLly7Fv3z6kp6fD3d0d69evR4sWLd543LBhw3D+/HmcOHECeXl5sLe3R1BQEKZMmQJnZ66YQbrTzM0eQ7o0wq4TfyL01B0M6dxI6EhERERUDYlUfFIKAK6+Qm+288RtnLiUiGFdGqFLS37xq2wcK0Ta4Vgh0o4+rr4i6JVyoqpiSEAjJKfnYVf0n7C1NEKzRvZCRyIiIqJqRLAbPYmqErFYhIm9PVGvtjl+3H8D955mCB2JiIiIqhEW5URakkkNMCPYFxYmUqwIj0VSeq7QkYiIiKiaYFFOVAaWplLMCvGFQqHE8rBY5OSVfCotERERUVmxKCcqo7p2ppg2wBvPU3KwOvIaFEVKoSMRERFRFceinKgcPN6zxtgejRH/MA2bD8eDixgRERHRu+DqK0Tl1M6rNuTpudh79h7srYzR16++0JGIiIioitJJUa5QKBAdHY309HT4+/vD3p7LxVHN0Pv9epCn5WLfuXuwszRCe+86QkciIiKiKqjMRfnixYtx4cIFREREAABUKhXGjBmDS5cuQaVSwcrKCqGhoXBxcdF5WCJ9IxKJMCrIAykZ+dh8OB425jI0rmcjdCwiIiKqYso8p/zs2bNo2bKl+vXJkyfxxx9/YNy4cfjuu+8AAOvXr9ddQiI9JzEQY2p/L9S2McHqPdfxOClb6EhERERUxZS5KH/27Bnee+899etTp07ByckJH3/8MXr27IkhQ4bg/PnzOg1JpO9MjAwxM8QHUokYy0NjkJ6VL3QkIiIiqkLKXJQXFhZCIvnfrJcLFy7g/fffV792dnaGXC7XTTqiKsTO0hgzQ3yQmVuAFeGxyC8oEjoSERERVRFlLspr166Nq1evAgD+/PNPPHr0CK1atVJvT05OhomJie4SElUh9WpbYHJfLzx4nokf99+AUsmlEomIiOjtynyjZ8+ePbF27VqkpKTgzz//hJmZGTp27KjeHhcXx5s8qUZr2tAOw7u6Yfux29gV/SeGdWkEkUgkdCwiIiLSY2UuyidNmoSnT58iOjoaZmZm+Pbbb2FhYQEAyMzMxMmTJzF69Ghd5ySqUgKaO0GeloujFx/B3soY3Vo5Cx2JiIiI9FiZi3KpVIpvvvmm1G2mpqY4d+4cjIyM3jkYUVUX4t8QSel5+CX6T9haGKGFO9fvJyIiotKVeU75mygUCpibm8PQ0FCX3RJVSWKRCBN6NUGDuhbYcOAGEp6kCx2JiIiI9FSZi/IzZ85g1apVGm07duxA8+bN0bRpU/z9739HYWGhzgISVWVSQwNMH+gDSzMpVobH4kVartCRiIiISA+VuSjftGkT7t69q36dkJCAb775Bg4ODnj//fcRFRWFHTt26DQkUVVmYSrFrBBfKJUqLA+NQVYuv7QSERGRpjIX5Xfv3oWXl5f6dVRUFGQyGcLDw7Fx40b06NEDe/fu1WlIoqqujq0ppg3wRlJ6LtZEXkOhQil0JCIiItIjZS7K09PTYW1trX7922+/oW3btjAzMwMAtG7dGomJibpLSFRNuLtYY2yPxrj1KA0/H46DSsU1zImIiOilMhfl1tbWePLkCQAgKysL165dQ8uWLdXbFQoFior4JEOi0rT1rI0BHRrg9xvPsffsPaHjEBERkZ4o85KITZs2xe7du9GwYUP8+uuvKCoqQocOHdTbHzx4AAcHB52GJKpOerZ7D0npuTjw233YWRnhA5+6QkciIiIigZX5SvmMGTOgVCoxa9YsREZGol+/fmjYsCEAQKVS4cSJE2jevLnOgxJVFyKRCB92c4dnfRtsPXILN+6nCB2JiIiIBCZSlWNia1paGq5cuQJzc3O0atVK3Z6eno69e/eiTZs28PDw0GnQipacnAWlsnLn+Nrbm0Muz6zUc5L+yM1XYNH2y0jOyMO84S3g5GAmdCS9xbFCpB2OFSLtCDVWxGIRbG1L//e+XEV5dcSinISQkpGHf229BLFYhPkjWsLaXCZ0JL3EsUKkHY4VIu3oY1Fe5jnlxR4+fIjo6Gg8evQIAODs7IzOnTvDxcWlvF0S1Tg2FkaYFeKLRTuuYEV4DOYObw4jabmHJREREVVR5bpSvnz5cmzYsKHEKitisRiTJk3CzJkzdRawsvBKOQkpNiEZK8Nj4dXABtMHesNAXObbPao1jhUi7XCsEGlHH6+Ul/lf/vDwcPzwww/w8fHBmjVrcOzYMRw7dgxr1qxB06ZN8cMPPyAyMvKdQxPVJD6utviwmxtiE5Kx8/ifXMOciIiohinz7+Q7d+6Er68vtm3bBonkf4e7uLigY8eOGD58OLZv344BAwboNChRddepmSPkabk4fOEh7K2MEdSGU8GIiIhqijJfKU9ISECPHj00CvJiEokEPXr0QEJCgk7CEdU0Azu5oqWHA0JP3cGl+BdCxyEiIqJKUuYr5YaGhsjJyXnt9uzsbBgaGr5TKKKaSiwSYUKvxkjLzMeGgzdhZS5DQ0dLoWMRERFRBSvzlXJvb2/88ssvSEpKKrEtOTkZoaGh8PX11Uk4oprIUGKA6QO9YW0uw8rwWLxIff2XYCIiIqoeyrz6yh9//IHRo0fD1NQUAwcOVD/N886dO4iMjER2djY2b96Mli1bVkjgisLVV0jfPE/JwcJtl2FqJMH8kS1hZlxzf4HiWCHSDscKkXb0cfWVci2JePLkSfzzn//E06dPNdrr1q2Lzz//HJ06dSpXUCGxKCd99GdiGpbs+g/q1zHHx0OawlBiIHQkQXCsEGmHY4VIO9WmKAcApVKJ69evIzExEcDLhwd5enoiNDQUW7duRVRUVPkTC4BFOemri3HP8cO+G2jd2AET+3hCLBIJHanScawQaYdjhUg7+liUl/vRgWKxGD4+PvDx8dFoT01Nxb1798rbLRH9RevGtZCcnoew0wmwtzLGwI6uQkciIiIiHePzvImqgKA2LpCn5eLQ+QewszRCx6aOQkciIiIiHWJRTlQFiEQiDO/mhqSMPGw7ehu2FkbwamArdCwiIiLSkTIviUhEwjAQi/FRXy842pti7d7rePic80aJiIiqCxblRFWIsUyCWSG+MJZJsCI8FqmZ+UJHIiIiIh3QavrKzz//rHWHV65cKXcYIno7a3MZZoX4YtH2y1geFoO5w5vDWMaZaERERFWZVv+Sf/vtt2XqVFQDl2wjqkzODmaY0t8Ly0NjsW7fdcwM9oGBmD98ERERVVVaFeVbt26t6BxEVEZe9W0xMsgdmw/HY/ux2xgZ6M4vxERERFWUVkV569atKzoHEZVDB9+66qUS7a2M0aPte0JHIiIionLgRFSiKq5/hwZISs9D+OkE2FkaoXXjWkJHIiIiojJiUU5UxYlFIozt0RipGXnYeDAOVmYyuDlbCR2LiIiIyoB3hhFVA4YSMaYN9IGtpRFWRcTieUqO0JGIiIioDFiUE1UTZsaGmB3iA5FIhGWhMcjIKRA6EhEREWmJRTlRNeJgbYKZwT5IzcrHqohYFBQWCR2JiIiItMCinKiacXW0xIReTXD3cQY2HoqDUqUSOhIRERG9BYtyomqopYcDBgU0xKX4F4g4nSB0HCIiInoLrr5CVE11a+UMeVouDl94CDsrY/g3cxQ6EhEREb0Gi3KiakokEmFol0ZITs/D9mO3YGshg4+rndCxiIiIqBScvkJUjRmIxZjU1xMuDuZYt/cGHjzLFDoSERERlYJFOVE1ZySVYGaID0yNJVgeHoOUjDyhIxEREdFfCFqUFxQUYMmSJfDz84OPjw8GDRqE8+fPv/W4Y8eOYdasWQgICICvry+CgoLw7bffIjOTVwGJSmNlJsOsEF8UFBZhWVgMcvIUQkciIiKiVwhalM+dOxdbtmxBnz59MH/+fIjFYkyYMAFXr15943GfffYZEhIS0LdvXyxYsAB+fn7Ytm0bhg4divz8/EpKT1S1ONmbYUp/bzxLzsG6vdegKFIKHYmIiIj+S6RSCbOIcWxsLEJCQjBv3jyMHj0aAJCfn49evXrBwcEBO3bseO2xFy5cQJs2bTTa9u7dizlz5mDRokUYMGBAmfMkJ2dBqazcj8Le3hxyOa/uU+U6G/sEP0fF4wOfOhjd3QMikUjoSG/FsUKkHY4VIu0INVbEYhFsbc1K31bJWdSOHDkCQ0NDhISEqNtkMhmCg4Nx+fJlvHjx4rXH/rUgB4AuXboAABISuCYz0Zt84FMXvd+vh7OxT3Ho/AOh4xAREREELMrj4uJQv359mJqaarT7+PhApVIhLi6uTP0lJSUBAKytrXWWkai66vdBfbTzrI3IX+/i9xvPhI5DRERU4wm2TrlcLketWrVKtNvb2wPAG6+Ul2bDhg0wMDBAt27ddJKPqDoTiUQY08MDqZl5+CkqDtbmMri78AstERGRUAQryvPy8mBoaFiiXSaTAUCZbtg8cOAAwsPDMWnSJLi4uJQrz+vm91Q0e3tzQc5LBABfTGiHT1adxZo917FkxgdwctDfv0eOFSLtcKwQaUffxopgRbmRkREKCwtLtBcX48XF+dtcunQJ8+fPR6dOnTBz5sxy5+GNnlRTTR/gjYVbL+GzH37DgpEtYWEqFTpSCRwrRNrhWCHSDm/0fIW9vX2pU1TkcjkAwMHB4a19xMfH46OPPoK7uzuWLVsGAwMDneckqu7srYwxI9gXGdkFWBkRi/zCIqEjERER1TiCFeUeHh64d+8esrOzNdpjYmLU29/k4cOHGD9+PGxsbPDjjz/CxMSkwrISVXcN6lpgYh9P3HuSgQ0Hblb6r0ZEREQ1nWBFeVBQEAoLCxEWFqZuKygoQGRkJJo3b66+CfTJkyclljmUy+UYO3YsRCIRNm3aBBsbm0rNTlQdNXezx5DOjXDlthyhp+4IHYeIiKhGEWxOua+vL4KCgrB06VLI5XK4uLhgz549ePLkCRYtWqTeb86cObh48SJu3bqlbhs/fjwePXqE8ePH4/Lly7h8+bJ6m4uLC5o1a1ap74WouujayhnytFwc++MR7K2M0bmFk9CRiIiIagTBinIAWLx4MZYvX459+/YhPT0d7u7uWL9+PVq0aPHG4+Lj4wEAGzduLLGtf//+LMqJ3sGQzo2QnJGHnSduw9bCCE0b2QkdiYiIqNoTqVQqTh4FV18helV+QREW77qCx0nZmDu8OerVthA0D8cKkXY4Voi0w9VXiKhKkEkNMCPYFxYmUqwIi0VSeq7QkYiIiKo1FuUCuPjsChb8+xsM/uUjLPj3N7j47IrQkYhKsDSVYlaILwoVSqwIi0VOXsnnChAREZFusCivZBefXcHO+AikFoE6WAAAIABJREFU5qdBBSA1Pw074yNYmJNeqmtniqkDvPEsJQdr9lyHokgpdCQiIqJqiUV5JdufcASFSs0rjoXKQuy5cwgFRQUCpSJ6vcbvWWNMDw/EPUjFlsPx4G0oREREuifo6is1UWp+WqntGQWZmH1mAaxklrA3toW9sR3sTWzhYGwHexM72BvbQmqgf48/p5rhfa86SErLw95z92BvZYw+fvWFjkRERFStsCivZNYyq1ILc1NDE/g7fQB5bhLkucm4lnQTmYVZGvtYSi3g8N8C/WWh/r//LWPBThWsd/t6kKflYu+5e7C1NEJ77zpCRyIiIqo2WJRXsj6uQdgZH6ExhcVQbIjgRn3QunZzjX1zFXkvi/ScZPX/f5GbhGvJcch8+teC3VxdqDsY28Huv1fZ7YxtYSSRVcp7o+pNJBJhVHcPpGTmY/PheNhYGKHx/7d379FxlfXewL97z/2a6+TaNjdo0vtNgYDc2nJOj4JFhFMtLQpYRYprgQtfAY9/eBRhaUGwAkKryxZ55bzUYrBrUQqUA0IRpHd6obRNaNIkTTK5zCWTue73jz2z55o0pU32TPL9rNWVZM+emWcCO/nOk9/z/KoK1B4WERHRhMB9yqPGc5/yDzv34JUT29Hv70e+IR9frVuWFsjPxhcaQo/Pia5BeWZdDu3y565A8r6beXobik3FGWbZC2HUGi/kS6NJYHAoiF/+eQ/63H48tHoRKostY/6c3HuZaHR4rRCNTjbuU85QHjWRmgcNhYbQ7etVgnpXwmx7amC3621JQV0J7qYiBnYaVs+ADw9v3g2tRsR/3bYIedax/WsMgwbR6PBaIRodhvIsNpFC+UiGQn5lZr0nWg4TC+8DKYHdprcq5TAOc3zxqcNUDBMD+6TX0unCoy/sQUWRBT9euRAGvWbMnotBg2h0eK0QjQ5DeRabLKF8JEMhP3p8Tjm0D8phPTbLPhBwJZ1r01mVXWFSy2IY2CePfZ/2YP3WA5h/UTHWfm0ORFEYk+fJtmuFKFvxWiEanWwM5VzoSQqj1oAptgpMsVWk3eYPB+TAnlIO80nfcXzQuTvpXKvOEg3qxSlbOxbBpDWN18uhcTD/4mKsXDodL7x+DC/u/BQrl05Xe0hEREQ5iaGcRsWg0aPSWo5Ka/o2eImBvVtZfDp8YHekLTqVS2LMOgb2XLRk0RR09/uw41+tcOSZcN0Xp6o9JCIiopzDUE7nbaTAHggH0OPrjc6u9yhbOw4f2ONBPd44iYE92/3n4ovgHBjCi29+iqI8IxZOd6g9JKJJ5ULs6kVE6mJNeRRrysdfIByM1rD3JGztKM+4pzZYsujM0X3Xi1FiTu54ataZVXoFlMgfDOPXf9mLti4P/s/KhaitsF+wx57s1wrRSD7s3JOx/8XKhq8zmBOlUPsNLBd6jgJDeXaJB3ZnwtaOcmDv9w9AQvy/lUVrjpfBJC0+LYaFgX1cubwB/GLzRwgEw/jJbV+AI//C/IWD1wpNVqFICJ6gF+6AF56AB+6gB+6A/E8+7sGR3mMIS+GM9xcFEQIECIIgfwSin4sQBAFi9DZEj8tfi9EzATF2PyHxMRI+j94HKV/LjykfS3qMUX4UER+TAFF5DAhQHl9IGKsgIPNjpYxJiI5VHM04MoxJeV2pjxEba9L3O3VMYvR7hZTvi5j+vR5mHGLC8yc+BmKfn+U1DP+a4mOdyLLhDSxD+SgwlOeOYDiInqFepXa9O6GevW+oPy2wx7qbJjVOMhfBqhv7pjeTUYfTi18+vxt2ix4PrV4Ei1F33o/Ja4UmiogUwWDQlxSu3UFPNHBHg7cSvr3whXwZH0cjaGDTW2HTWdDqaR/2+ZZVLUYEEiRJgpT4Me0YIEkR5evYfeQxS5AQSbgvUu4bgSQh7TEjkIDo15GE44CUeUxn+Rh7DETHmv4YSBjPcGNl5BlJenhPPCbGj6W9gUp/o3Dub8IyvNnI+AYKKePJPFYx7c2mgI/O7IM/HEh73QWGfPziiofG5XvM3VdoQtFpdCi3lKLcUpp2WzAchFMJ7PI+7D2DTpwYaMFHZ/Yl/UA2a01Je68nLj61aM0TfsZgrJQXWXDPTXPw2P/sw1NbD+K+/5wPnVZUe1hEY0KSJAyFh+SZ7MSgHfBmDNueoDdjMBQgwKIzR4O2FVOtlbBGQ7dVb1WO2/QWWHVWmLRG5WfUf733y7SSP0AOGjfULRvz70GuSX3jcNY3BalvNqJvLDK+2Tjrm5/Y/eNvgpQ3GxKi44kknJ/6ZieSdjyS8PzDvqazvM7EN1Bpj5HxPoiPJ+1NkZT0Rg7A53oTFpYiw74unO11pn6vo2PNFMgBZLx+1MBQThOKTqNDmaUUZZkCeyQEZ1KnU3mGvXngM+w+sz/pF6VJa0pomhSrYZcbKVl0DOxnUz+tAHd8eQae+/th/OnVI/jO9TP5PaOcEQgHkwN2Sqh2J5SReAIehIYpHTFpjbDprLDq5b4OtXlV0aAth2ub3gqrTg7cFp0ZovD53rx+tW5Zxj/Jf5WBPKN4GQswdi3PKBuN9AY2GzCU06ShE7Uos5SgzFKSdltqYI9t7dg8cCpDYDdG92CP167HatmtOgvDZ9Rls8rQMzCEre+chCPfhBuvrFV7SDRJhSNheILeeKBOCtUJM9rR48PNpulEnTJjnae3odJaHg3dlmjQjv+z6CzQiePzKzZWC8vdV4hGlu1vYFlTHsWachpOSAnszqTGSd2DPXAO9WUI7EVJQT0W3CdjYJckCX969Sj+caADd3x5Br40N33bzNHgtUKJIlIEgyGfHKgTa7ITZ7WjNdmegAfe0GDGxxEFMV4ekhCqrTpLwufx4waNfpxf6bnjtUI0smzefYUz5URnoRW1KLWUoDTDDHsoEoJzqC+tcdJn7jbs7T6IiBRRzjVqjPHupimLTm0664QM7IIgYPW/16PXNYRN24+i0G7AzOpCtYdFWUaSJPjD/uS67IRQLYdub3x2O+hNurZiBAgw60xKwK6wlmWeyY6GbpPWNCGvOyIa3iVlC3FJ2cKsfAPLmfIozpTThRaKhNA71JewB7s8y97l60HvUF9KYDekBPX4LPtECOyDQyE8+sJuOF1DeHDVIkxxZJ4lGA6vldwTDAflcpGUcJ26nZ/8uQfBSCjj4xg1hpSZbItSp520CFJvhUVrhkac3FXCvFaIRketa4VbIo4CQzmNp3AkDOdQb8LsenJJTKbAXpyh06ldnzuBvdc1hJ9v/ghaUcBPbvsC8q2GUd+X14r6wpEwvKHBpJKR2ELH1Jlsd8CLofBQxsfRitr4LiLDlY3o4l/rNOe/peZkwmuFaHQYyrMYQzllCzmw9yXsv96jbO3YM9SbFNgNGr2y6DQW1GNbO9r1tqwL7J91uvHoC3tQVmjGj29dAKN+dBV0vFYuPEmS4Av5MtRhZ97OzxsczLiVnyiI8lZ+SeUhGWayo0HcoDFk3f+XEwmvFaLRYSjPYgzllAvCkTB6h/qTgnqXTw7uPb7kwK7X6JVFp8oe7NEa9jy9XbVgdOBED57ccgBzaovwg6/PgUY8+zZwvFZGxx8OKOUgsXCdGLaTS0a8w3aBtGjNsEb3w06tw7amfG7Wmj73Vn504fFaIRqdbAzlXOhJlEM0okbeO91chJmoT7otHAmjz98fL4eJzrK3eztwsOdwUgDTi7p4/bqyQ4w82z7WgX1uXTFW/Vs9nn/tE/zfNz7Fquumc+Z0GPEW66nlIZm7QAYStvlKZNDolYBdYMzDNFulMoOdqWRkstdlExGpgaGcaILQiBoUm4pQbCpKu00O7ANJ5TDdg050eDszBvbipD3Y47Ptdr3tgsyKXrugEt39Pmz/4BRK8k3490umnfdj5oKIFIE3OJjWhGa47fyGa7GuFTRJ5SGlZkdSqE7ezs8CfQ5s5UdENNkxlBNNAnJgL0SxqRAzMD3ptogUUUpiErd27PB24eOeI0ndCnWiTplRj2/tKIf2PIP9nAL7zdfUoWdgCP9v53EU2Y34QkP6lpPZLt5i3ZPSZv3cW6xbdRZl6754i/XUBZFy4DZqjPzrAhHRBMNQTjTJiYIYD+yF6YG9b6g/aQ/2bl8Pzni7cGi4wK4sOo3PtmcK7KIg4DtfmYF+tx8bth1Ggc2Ausq8cXnNIwmEg8l12QmhOrU2e+QW6yY5UOviLdbTarIvQIt1IiKaGLjQM4oLPYnOjRzYB5Sg3q0sOnWix+dEKGHfaZ2olUtiTMUoVhooyaUxmrAJj/x5L3z+EH6yehFKCszK/S5E57VYi/V4qYg383Z+o2ixbk8oCRmpC+R4tlgnSsTfK0Sjk40LPRnKoxjKiS6ciBRBv38gZdGpHNpTA7tW1KJAX4DuMyL0ETu+smgmpthL0OE9g6YTryKYsHhRJ+rwzfqbMKu4Ib0OO/p54u4iZ2+xnh6ole38UnYfyYUW60T8vUI0OgzlWYyhnGh8xAJ796AzaWvHNtcZ9Az1QhDT26ePhgABFp05eX/shDrsxL2z2WKdJir+XiEanWwM5fz7KhGNK1EQUWgsQKGxAPW4KOm2Dw534rntuzGz3oCTph3DPsbNF381vWSELdaJiCiHMZQTUda4dGYZnK7Z2PK/J5B/iRV+eNLOKTDk49qpX1JhdERERGOHy/2JKKv8x6XTcPX8CriP10KTMm+gE3X4at0ylUZGREQ0dhjKiSirCIKAVf82HTPyZ8N3fCYQMEGSACFowiXWpee8+woREVEuYPkKEWUdjShi0XQHDm2vgK+3Qjn+jlZAjakTjbPKVBwdERHRhceZciLKStt2taT1vgyEIvifNz+Fzx/KeB8iIqJcxZlyIspKTpc/43HXYBD3/OYdlBWZUVtuR3W5HbUVdkxxWKHTcp6BiIhyE0M5EWWlIrshYzC3mXVYumgKmjvcONjci/c+7gQAaDUCppZYUVNuV/6VFZkhci9yIiLKAQzlRJSVbrq6DptePYpAKN5MSK8V8Y0lFys15ZIkoc/tx8l2F5o7XWhud2HXx53Yuec0AMCo16C6zIaaCjtqyuQZ9QKbgU2DiIgo6zCUE1FWigXvrW+fQK/Lj0K7ATddXZe0yFMQBBTajSi0G/GFhhIAQESS0OkcRHOHCyc7XGjpcGHHh60IRzv22i161JbbUVNuQ020/MVq0o3/CyQiIkogSJI0vr3ls5TT6UEkMr7fCrZDJhqd871WgqEI2ro98ox6h/yv0zmoLCQtyTfJs+nRsD6t1AaDjt1BKffw9wrR6Kh1rYiigKIia8bbOFNORBOeTisqdeYxPn8ILZ1uOaS3u/BpWz8+OHwGACAKAiodFtREF5FWl9lQ6bBAI3IhKRERjQ2GciKalEwGLWZUFWBGVYFybMDjR3OHGyejs+m7P+nCO/vbAcj17NPKbNHSF3lG3ZFvYn06ERFdEAzlRERReVYD5l9swPyLiwHIC0m7+n1obnehuUOeVX9r72ns+FcrAMBi1MZ3e4mWv+RZ9Gq+BCIiylEM5UREwxAEAaUFZpQWmHFZdIFpKBxBe49XqU0/2e7GtvdbEFudU2Q3yHunR8N6VZkNJgN/1BIR0cj4m4KI6BxoNSKmlcqLQa+eXwkA8AfC+OyMGy3RHV/k0pduAIAAoLzYgprY1ozldkwtsUKrYX06ERHFMZQTEZ0ng16D6VPzMX1qvnLMPRiQF5JGd3w5eNKZ0ujIpmzLWFthR2khGx0REU1mDOVERGPAZtZjTm0R5tQWAZDr03td/qT9099LaHRkMmhQXWZHdXl8MSkbHRERTR4M5URE40AQBBTlGVGUl9DoKCKho3dQmU1vTml0lGfRKzu91FTYUV3GRkdERBMVQzkRkUpEUUBlsQWVxRZ8aW45ACAYCqO1yxtdROpCS6cL+473KPcpKTChNtqJtLbcjmmlVujZ6IiIKOcxlBMRZRGdVoPaCrnOfMki+djgUAifdcYWkbrxSWs//pnQ6GiKw5LQkdSOimIzGx0REeUYhnIioixnNmoxo7oQM6oLlWP9Hr9S8tLc7sK/jnTh7X3RRkc6EVWltqQ91B15RtanExFlMYZyIqIclG81YMHFDiy42AEg2uioz6csJE1tdGQ16ZIWkdaU22FnoyMioqyhaigPBAJ48skn0dTUBJfLhYaGBtx3331obGwc8X4HDhzA1q1bceDAARw7dgzBYBCffPLJOI2aiCj7CIKA0kIzSguTGx2d7vaiudOlLCb9e3NioyOjsoi0poyNjoiI1KTqT98HHngAO3bswG233Yaqqiq8/PLLWLNmDZ5//nksWLBg2Pu9/fbbeOmll1BfX4+pU6fi5MmT4zhqIqLcoNWIqCqzoarMhmtSGh3FO5K68FFCo6OKYosyo17NRkdERONGkKTYnMn4OnDgAG655RY8+OCD+Pa3vw0A8Pv9uP7661FSUoIXXnhh2Pv29PTAarXCaDTi4YcfxubNm897ptzp9CASGd9vhcNhQ3e3e1yfkygX8VoZW+7BAJo74kG9ucMF92AQgNzoaFqpDTVldtRUyHXqbHSUvXitEI2OWteKKAooKrJmvE21mfLt27dDp9PhlltuUY4ZDAbcfPPN+M1vfoOuri6UlJRkvG9xcfF4DZOIaMKzmfWYW1eEuXXxRkdO15Ac1KNlL+8e7MCbe9oAxBsdxWrTayvkRkdERPT5qRbKjxw5gpqaGlgslqTjc+fOhSRJOHLkyLChnIiIxo4gCCjOM6E4z4QvJjY6cnqVbRmbO1x47cNT8UZHVn3S/unV5TZYjGx0REQ0WqqF8u7ubpSWlqYddzjknQS6urrGe0hERDQMURRQ6bCi0mHFlXPlY8FQGKe6PAkdSd3Y+2m80VFpgUlZRFpTYce0EjY6IiIajmqhfGhoCDpd+iyKwSD/CdTv94/reIar7xlrDodNleclyjW8VrJTRXk+LpsX/9rjC+JEaz+Otfbh2Kk+fNraj38ekhsdaUQBVeV2TJ9WgIun5mP6tAJMLbVBI7I+/ULitUI0Otl2ragWyo1GI4LBYNrxWBiPhfPxwoWeRNmL10puqSgwoqKgHNfMLQcA9Ln9aEnYP/3tPW3Y/n4LAMCg06Cq1JrUkbSYjY4+N14rRKPDhZ4JHA5HxhKV7m55ay7WkxMRTQwFNgMKbA4smC6XJ0YSGh3FSl/e3H0aoXC80ZEc0G1sdEREk4ZqobyhoQHPP/88vF5v0mLP/fv3K7cTEdHEIwoCygrNKCs0ozGl0dHJhG0ZP252Ko2OivOMyiLSmnJ573Wjno2OiGjiUO0n2rJly/DHP/4RL730krJPeSAQwNatW7Fw4UJlEWh7ezt8Ph/q6urUGioREY2xxEZH1y6QGx0NBUL4rNOdtIf6R0flv7AKgtzoKLaItKbchikONjoiotylWiifN28eli1bhnXr1qG7uxvTpk3Dyy+/jPb2djzyyCPKeT/+8Y/x4YcfJjUHOn36NJqamgAABw8eBAA8/fTTAOQZ9sWLF4/jKyEiorFg1GtRP60A9dMKlGOuwQBaErZl3He8B+8e7AAQDfal1qRtGdnoiIhyhap/+/vVr36FJ554Ak1NTRgYGEB9fT2ee+45LFq0aMT7tbW14cknn0w6Fvv6a1/7GkM5EdEEZTfrMbeuGHPr5CZykiTBOTCUUPbixrsHOvDm7lijI21SbXpNORsdEVF2EiRJGt8tR7IUd18hyl68VuhcRCIS2p3epP3T27o9SqOjfKs+HtIr7Kgps8E8QRod8VohGh3uvkJERDTGRFHAFIcVUxxWXDmvAgAQCIbR2uVJmlFPanRUaEZtuU0pfZlWaoVOy0ZHRDR+GMqJiGjC0+s0qKvMQ11lnnLMOxRES6dbmVE//Fkf3k9odDTFYVVm0msq7KgoskBkoyMiGiMM5URENClZjDrMqi7ErOpC5Vif24+T7S60dLpwst2FDw6fwf/uPQ0g2uiozKYsIq0tt6OIjY6I6AJhKCciIooqsBmwqN6BRfXxRkdnegfR0uFWSl/e2N2GUDgCQG50VKt0I5XLX+xmNjoionPHUE5ERDQMURBQXmRBeZEFjbPjjY7auj3ytozR0peDJ5yIbRVQnGdM2O2FjY6IaHT4U4KIiOgcaDUiqsvsqC6zK42OfP4QTp2Jzaa7cbLdhX+lNjpSOpLaUemwsNERESVhKCciIjpPJkOGRkfegNKJtLnDjX2f9uDdA3KjI51WxLQSa3xbxnI7SgpMbHRENIkxlBMREY0Bu0WPeRcVY95F8UZHPQNDaO6QF5G2dLjwzoF2vBFtdGQ2aFEdbXQkLyZloyOiyYShnIiIaBwIggBHvgmOfBMumVEKAAhHIujoGUzYP92FV/95CpFoX78CmwHVZTZlMWl1mR1mY/qv7vcPdWLr2yfQ6/Kj0G7ATVfXoXFW2bi+PiI6PwzlREREKtGIIqaUWDGlxIqrEhodneryJHQkdSU1OiorNKMmOqNeU2FHR48Xf95xDIGQvCOM0+XHplePAgCDOVEOYSgnIiLKInqdBhdV5uGi1EZHsW0Z21043BJvdJRJIBTBlrdO4JIZJdCIXFBKlAsESZKks5828TmdHkQi4/utcDhs6O52j+tzEuUiXitEySRJQp/bj+YON556+eCw5wkCYDfrkWfVI99qQH70Y57VgHyLHvk2A/Isetgteu4GQ5OKWr9XRFFAUZE1422cKSciIsoxgiCg0G5Eod2IIrsBTpc/7RyLUYvFC6dgwOtHvyeAfo8fLZ1uuL0BpE5BCQBsZp0c1q2GDCFej3yL/JHhnWhsMJQTERHlsJuursOmV48qNeUAoNeKWHnd9Iw15eFIBC5vEP0ePwaiYV3+F8CAx49+bwCnutxweQPI9Ld0q0mnBPZ4eI99Hf1oMUCnZXgnOhcM5URERDksFrxHu/uKRhRRYDOcdbvFSESCazCAAU8AfR4/BpJCvPzxdI8XA56AsltMIotRi3xbtEwmWjKTZ9WjIGUmXqfVnP83gWgCYCgnIiLKcY2zytA4q+yC1smKoqDMglfBNux5kYgEty8oz7InBPbEAN/R24cBTwDhDGu3LEatHNgtGUpmEmbgDTqGd5rYGMqJiIjocxNFAXkWPfIsekwrHSG8SxI8vmDmkpnox2Ot/ej3+DOGd5NBm1bjnlgyEztu1DPaUG7i/7lEREQ05kRBgN2sh92sx9SSzLtPAPLOMt6hEPrdfvR7/eh3B5IWqw54AjjeNoB+TwChcCTt/ka9BnlWAwqigX24GXiTgRGIsgv/jyQiIqKsIQgCrCYdrCYdpmDk8D7oj4X3APrdfgxEP/Z75Zn3k+0DGPAEkhbBxhh0mmF3mYnPwBtgMmggCMJYvmQiAAzlRERElIMEQYDFqIPFqEOlY/jzJEmCzx9KrnVPnIF3y1tF9nt6EAimh3e9VlQCe2KpTGJwz7fqYTZoGd7pvDCUExER0YQlCALMRh3MRh0qii3DnidJEoYC4bRa935PfAa+tcuDgyf98AfCaffXacWkUpnUWvfYolmLkeGdMmMoJyIioklPEASYDFqYDFqUFw0f3gHA5w9hwJsS3BMWsJ7u8eJQSy98/vTwrtUIyLOkB/bE4J5n1cNq0kFkeJ9UGMqJiIiIzkEsvJcVmkc8zx8Io9+bvD1k4taR7U4vjnzWh0F/KO2+GlGQS2Ysw5fM5FkNsJkZ3icKhnIiIiKiMWDQa1CqN6O0YOTwHgiGlcWp/Qkz7gPREN/V58Ox1n54hzKHd7tFr3RSzVQyk2eVd70RRYb3bMZQTkRERKQivU6DknwTSvJNI54XDIWjC1UTdptJmHnvGfDh+OkBeHzBtPsKAqLhPdpl1Za4XWQ8xNstOmhEcaxeKo2AoZyIiIgoB+i0GhTnm1B8lvAeCkeSSmbkxarxz3vdfpzscME9mCG8Qw7vSR1VLQbk2+QwH1vAarfoodUwvF9IDOVEREREE4hWI6Ioz4iiPOOI54XCEbi8gbRad2XHGY+8XaTbG0Bqj1UBgM2skxs0pe73bjEg3ybv+Z5nZXgfLYZyIiIioklIqxFRaDei0D5yeA9HInB5g0m17qlbR7Z2eeDyBiClpncAVpMuc617tIwmNgOv007u8M5QTkRERETD0ogiCmwGFNgMI54XiUhwDQYw4Amgz+NXAnviAtbTPV4MeAKIZEjvFqM2bZeZvNSdZyx66HWaz/1a3j/Uia1vn0Cvy49CuwE3XV2Hxllln/vxLiSGciIiIiI6b6IoKLPgVbANe14kIsHtC0YXq2ba6z2Ajt4+DHgCCEfSw7vZoE1YqBqbgU/fecaQEt7fP9SJTa8eRSAkd251uvzY9OpRAMiKYM5QTkRERETjRhQF5Fn0yLPogZHCuyTBo4R3eceZxK0jBzx+HGvtR/8w4d1k0CSVyez7tEcJ5DGBUARb3z7BUE5ERERElIkoCLCb5T3WRyJFw7u8XaQf/e6APAPvDijNm463DWAokN5hFZBnzLMBQzkRERER5SxBEGAz62Ez6zEF1mHP+9HT72UM4EX2kWvlx8vkXuZKRERERJPCTVfXQZ+yw4teK+Kmq+tUGlEyzpQTERER0YQXqxvn7itERERERCpqnFWGxlllcDhs6O52qz2cJCxfISIiIiJSGUM5EREREZHKGMqJiIiIiFTGUE5EREREpDKGciIiIiIilTGUExERERGpjKGciIiIiEhlDOVERERERCpjKCciIiIiUhk7ekaJojCpnpco1/BaIRodXitEo6PGtTLScwqSJEnjOBYiIiIiIkrB8hUiIiIiIpUxlBMRERERqYyhnIiIiIhIZQzlREREREQqYygnIiIiIlIZQzkRERERkcoYyomIiIiIVMZQTkRERESkMoZyIiIiIiKVMZQTEREREalMq/YAJpuuri5s3rwZ+/fvx8cff4zBwUFs3rwZl156qdpDI8oaBw4cwMsvv4wPPvgA7e3tyM/Px4IFC3DvvfeiqqpK7eHOaLFgAAAJFUlEQVQRZY2DBw/i97//PQ4fPgyn0wmbzYaGhgasXbsWCxcuVHt4RFltw4YNWLduHRoaGtDU1KT2cBjKx1tzczM2bNiAqqoq1NfXY+/evWoPiSjrbNy4EXv27MGyZctQX1+P7u5uvPDCC7jxxhuxZcsW1NXVqT1EoqzQ2tqKcDiMW265BQ6HA263G3//+9+xatUqbNiwAVdccYXaQyTKSt3d3XjmmWdgNpvVHopCkCRJUnsQk4nH40EwGERBQQHeeOMNrF27ljPlRCn27NmD2bNnQ6/XK8daWlpwww034Ctf+QoeffRRFUdHlN18Ph+WLl2K2bNn49lnn1V7OERZ6YEHHkB7ezskSYLL5cqKmXLWlI8zq9WKgoICtYdBlNUWLlyYFMgBoLq6GhdffDFOnDih0qiIcoPJZEJhYSFcLpfaQyHKSgcOHMArr7yCBx98UO2hJGEoJ6KcIEkSenp6+KaWKAOPx4Pe3l6cPHkSjz/+OI4dO4bGxka1h0WUdSRJws9//nPceOONmDFjhtrDScKaciLKCa+88grOnDmD++67T+2hEGWdhx56CK+99hoAQKfT4Rvf+AbuuusulUdFlH3+9re/4fjx43jqqafUHkoahnIiynonTpzAf//3f2PRokVYvny52sMhyjpr167FihUr0NnZiaamJgQCAQSDwbQyMKLJzOPx4LHHHsN3v/tdlJSUqD2cNCxfIaKs1t3dje9973vIy8vDk08+CVHkjy2iVPX19bjiiivw9a9/HX/4wx9w6NChrKuXJVLbM888A51Oh9tvv13toWTE325ElLXcbjfWrFkDt9uNjRs3wuFwqD0koqyn0+mwZMkS7NixA0NDQ2oPhygrdHV1YdOmTVi5ciV6enrQ1taGtrY2+P1+BINBtLW1YWBgQNUxsnyFiLKS3+/HXXfdhZaWFvzpT39CbW2t2kMiyhlDQ0OQJAlerxdGo1Ht4RCpzul0IhgMYt26dVi3bl3a7UuWLMGaNWtw//33qzA6GUM5EWWdcDiMe++9F/v27cPTTz+N+fPnqz0koqzU29uLwsLCpGMejwevvfYaysvLUVRUpNLIiLLLlClTMi7ufOKJJzA4OIiHHnoI1dXV4z+wBAzlKnj66acBQNlvuampCbt374bdbseqVavUHBpRVnj00Uexc+dOXHvttejv709q6mCxWLB06VIVR0eUPe69914YDAYsWLAADocDHR0d2Lp1Kzo7O/H444+rPTyirGGz2TL+7ti0aRM0Gk1W/F5hR08V1NfXZzxeWVmJnTt3jvNoiLLP6tWr8eGHH2a8jdcJUdyWLVvQ1NSE48ePw+VywWazYf78+bjjjjtwySWXqD08oqy3evXqrOnoyVBORERERKQy7r5CRERERKQyhnIiIiIiIpUxlBMRERERqYyhnIiIiIhIZQzlREREREQqYygnIiIiIlIZQzkRERERkcoYyomISDWrV6/G4sWL1R4GEZHqtGoPgIiILqwPPvgAt91227C3azQaHD58eBxHREREZ8NQTkQ0QV1//fW46qqr0o6LIv9ISkSUbRjKiYgmqJkzZ2L58uVqD4OIiEaB0yVERJNUW1sb6uvrsX79emzbtg033HAD5syZg2uuuQbr169HKBRKu8/Ro0exdu1aXHrppZgzZw6+/OUvY8OGDQiHw2nndnd34xe/+AWWLFmC2bNno7GxEbfffjvee++9tHPPnDmDH/7wh/jiF7+IefPm4c4770Rzc/OYvG4iomzEmXIiognK5/Oht7c37bher4fValW+3rlzJ1pbW3HrrbeiuLgYO3fuxO9+9zu0t7fjkUceUc47ePAgVq9eDa1Wq5z71ltvYd26dTh69Cgee+wx5dy2tjZ885vfhNPpxPLlyzF79mz4fD7s378fu3btwhVXXKGcOzg4iFWrVmHevHm477770NbWhs2bN+Puu+/Gtm3boNFoxug7RESUPRjKiYgmqPXr12P9+vVpx6+55ho8++yzytdHjx7Fli1bMGvWLADAqlWrcM8992Dr1q1YsWIF5s+fDwB4+OGHEQgE8OKLL6KhoUE5995778W2bdtw8803o7GxEQDws5/9DF1dXdi4cSOuvPLKpOePRCJJX/f19eHOO+/EmjVrlGOFhYX49a9/jV27dqXdn4hoImIoJyKaoFasWIFly5alHS8sLEz6+vLLL1cCOQAIgoDvfOc7eOONN/D6669j/vz5cDqd2Lt3L6677jolkMfO/f73v4/t27fj9ddfR2NjI/r7+/GPf/wDV155ZcZAnbrQVBTFtN1iLrvsMgDAZ599xlBORJMCQzkR0QRVVVWFyy+//Kzn1dXVpR276KKLAACtra0A5HKUxOOJamtrIYqicu6pU6cgSRJmzpw5qnGWlJTAYDAkHcvPzwcA9Pf3j+oxiIhyHRd6EhGRqkaqGZckaRxHQkSkHoZyIqJJ7sSJE2nHjh8/DgCYOnUqAGDKlClJxxOdPHkSkUhEOXfatGkQBAFHjhwZqyETEU04DOVERJPcrl27cOjQIeVrSZKwceNGAMDSpUsBAEVFRViwYAHeeustHDt2LOnc5557DgBw3XXXAZBLT6666iq888472LVrV9rzcfabiCgda8qJiCaow4cPo6mpKeNtsbANAA0NDfjWt76FW2+9FQ6HA2+++SZ27dqF5cuXY8GCBcp5P/nJT7B69WrceuutWLlyJRwOB9566y28++67uP7665WdVwDgpz/9KQ4fPow1a9bgxhtvxKxZs+D3+7F//35UVlbiRz/60di9cCKiHMRQTkQ0QW3btg3btm3LeNuOHTuUWu7FixejpqYGzz77LJqbm1FUVIS7774bd999d9J95syZgxdffBG//e1v8Ze//AWDg4OYOnUq7r//ftxxxx1J506dOhV//etf8dRTT+Gdd95BU1MT7HY7GhoasGLFirF5wUREOUyQ+HdEIqJJqa2tDUuWLME999yDH/zgB2oPh4hoUmNNORERERGRyhjKiYiIiIhUxlBORERERKQy1pQTEREREamMM+VERERERCpjKCciIiIiUhlDORERERGRyhjKiYiIiIhUxlBORERERKQyhnIiIiIiIpX9fwvYKxjhRG8aAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DosV94BYIYxg"
      },
      "source": [
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using [Matthew's correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html) because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387206ba-39fc-4e2f-9fca-0c29000fd8de"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences_test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = max_seq_length,  # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "labels_test = torch.tensor(labels_test)\n",
        "\n",
        "# Create the DataLoader.\n",
        "test_data = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "test_dataloader = DataLoader(test_data, sampler=SequentialSampler(test_data), batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715f5d69-dce9-4483-a9b8-d6eb8470c875"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_test)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 200 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWcy0X1hirdx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ae26c5-5b4a-4eaf-aaa0-adc0f08b28b8"
      },
      "source": [
        "n_tot = len(df_test.labels_test)\n",
        "if num_labels == 2:\n",
        "  n_pos = len(df_test[df_test.labels_test == 0])\n",
        "  n_neg = len(df_test[df_test.labels_test == 1])\n",
        "  print('positive samples: %d of %d (%.2f%%)' % (n_pos, n_tot, n_pos/n_tot * 100.0))\n",
        "  print('negative samples: %d of %d (%.2f%%)' % (n_neg, n_tot, n_neg/n_tot * 100.0))\n",
        "\n",
        "elif num_labels == 3:\n",
        "  n_pos = len(df_test[df_test.labels_test == 0])\n",
        "  n_neg = len(df_test[df_test.labels_test == 1])\n",
        "  n_neu = len(df_test[df_test.labels_test == 2])\n",
        "  print('positive samples: %d of %d (%.2f%%)' % (n_pos, n_tot, n_pos/n_tot * 100.0))\n",
        "  print('negative samples: %d of %d (%.2f%%)' % (n_neg, n_tot, n_neg/n_tot * 100.0))\n",
        "  print('neutral samples: %d of %d (%.2f%%)' % (n_neu, n_tot, n_neu/n_tot * 100.0))\n",
        "\n",
        "else: \n",
        "  'enter correct value of num_labels'  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive samples: 150 of 200 (75.00%)\n",
            "negative samples: 50 of 200 (25.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1318ca4-fdc0-454a-afab-4e7491b3fa41"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  # print(i, true_labels[i], pred_labels_i)\n",
        "  # print(i, true_labels[i]-pred_labels_i)\n",
        "\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ9XtkLysrye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "cd992239-fd67-407f-f58a-f2a4aa2ec8d8"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentences_test</th>\n",
              "      <th>labels_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It will focus on improving its profitability n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Furthermore , Bunge will also sign a licensing...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to Swedish authorities , traces of t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finnish retailer Stockmann has won approval fr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>To ensure low operational cost for radio netwo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>Revenue grew 12 percent to (  x20ac ) 3.6 bill...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>So far , Mr. Galvan he has been able to avoid ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Last year 's net sales rose to EUR 68.3 millio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Vaisala also said it expects net sales of EUR ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>Finnish-Swedish Stora Enso does not understand...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        sentences_test  labels_test\n",
              "0    It will focus on improving its profitability n...            0\n",
              "1    Furthermore , Bunge will also sign a licensing...            0\n",
              "2    According to Swedish authorities , traces of t...            1\n",
              "3    Finnish retailer Stockmann has won approval fr...            0\n",
              "4    To ensure low operational cost for radio netwo...            0\n",
              "..                                                 ...          ...\n",
              "195  Revenue grew 12 percent to (  x20ac ) 3.6 bill...            0\n",
              "196  So far , Mr. Galvan he has been able to avoid ...            0\n",
              "197  Last year 's net sales rose to EUR 68.3 millio...            0\n",
              "198  Vaisala also said it expects net sales of EUR ...            0\n",
              "199  Finnish-Swedish Stora Enso does not understand...            1\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyfY1tqxU0t9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "93513003-3b90-4e9f-f93b-923a59a6d914"
      },
      "source": [
        "# Create a barplot showing the MCC score for each batch of test samples.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC Score per Batch')\n",
        "plt.ylabel('MCC Score (-1 to +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YrjAPX2V-l4"
      },
      "source": [
        "Now we'll combine the results for all of the batches and calculate our final MCC score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCYZa1lQ8Jn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf2f43f6-03f1-431a-c204-cea59c7b7daa"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "conf_mat_list = confusion_matrix(flat_true_labels, flat_predictions)\n",
        "conf_mat_test = pd.DataFrame(conf_mat_list)\n",
        "\n",
        "print(classification_report(flat_true_labels, flat_predictions))\n",
        "print(confusion_matrix(flat_true_labels, flat_predictions))\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       150\n",
            "           1       0.96      0.90      0.93        50\n",
            "\n",
            "    accuracy                           0.96       200\n",
            "   macro avg       0.96      0.94      0.95       200\n",
            "weighted avg       0.96      0.96      0.96       200\n",
            "\n",
            "[[148   2]\n",
            " [  5  45]]\n",
            "Total MCC: 0.906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "WlzjkzTzjZ1A",
        "outputId": "b75b988f-a3a0-4588-d337-925d8a5a1017"
      },
      "source": [
        "sns.heatmap(conf_mat_test, annot=True, fmt=\"d\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fecf512-7a46-4f0a-ba19-0772f58bb7d3"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxlZsafTC-V5"
      },
      "source": [
        "# Copy the model files to Google Drive.\n",
        "!cp -r ./model_save/ '/content/drive/My Drive/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nskPzUM084zL"
      },
      "source": [
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "# model = model_class.from_pretrained(output_dir)\n",
        "# tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# # Copy the model to the GPU.\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}